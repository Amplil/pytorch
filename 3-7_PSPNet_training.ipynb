{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"3-7_PSPNet_training.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"g7fOv9Gc5Dkg"},"source":["# 3.7 学習と検証の実施\n","\n","- 本ファイルでは、PSPNetの学習と検証の実施を行います。AWSのGPUマシンで計算します。\n","- p2.xlargeで約12時間かかります。\n"]},{"cell_type":"markdown","metadata":{"id":"QYZ3dHjo5Dkh"},"source":["# 学習目標\n","\n","1.\tPSPNetの学習と検証を実装できるようになる\n","2.\tセマンティックセグメンテーションのファインチューニングを理解する\n"]},{"cell_type":"markdown","metadata":{"id":"2kCZ8pIO5Dki"},"source":["# 事前準備\n","\n","- 本書に従い学習済みモデルのファイル「pspnet50_ADE20K.pth」をダウンロードし、フォルダ「weights」に用意します。"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"52JWN6BMsfwO","executionInfo":{"status":"ok","timestamp":1614143965504,"user_tz":-540,"elapsed":41528,"user":{"displayName":"Operational Amplifier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3etudnjCRnCXOZeYBsRUFbwA5_hCPRQvY_sSe=s64","userId":"13448740953613370666"}},"outputId":"f22c6d1f-2460-4858-d363-d570f60bd8c8"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YMiQ1egPsLPR","executionInfo":{"status":"ok","timestamp":1614143969299,"user_tz":-540,"elapsed":887,"user":{"displayName":"Operational Amplifier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3etudnjCRnCXOZeYBsRUFbwA5_hCPRQvY_sSe=s64","userId":"13448740953613370666"}},"outputId":"bfae9956-599c-43cb-afcb-66f34e0b6b84"},"source":["cd \"/content/drive/My Drive/Colab Notebooks/pytorch_advanced/3_semantic_segmentation\""],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/pytorch_advanced/3_semantic_segmentation\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aokMFYco5Dki","executionInfo":{"status":"ok","timestamp":1614143980281,"user_tz":-540,"elapsed":4144,"user":{"displayName":"Operational Amplifier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3etudnjCRnCXOZeYBsRUFbwA5_hCPRQvY_sSe=s64","userId":"13448740953613370666"}}},"source":["# パッケージのimport\n","import random\n","import math\n","import time\n","import pandas as pd\n","import numpy as np\n","\n","import torch\n","import torch.utils.data as data\n","import torch.nn as nn\n","import torch.nn.init as init\n","import torch.nn.functional as F\n","import torch.optim as optim"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"wvHo-7O-5Dkl","executionInfo":{"status":"ok","timestamp":1614143987888,"user_tz":-540,"elapsed":583,"user":{"displayName":"Operational Amplifier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3etudnjCRnCXOZeYBsRUFbwA5_hCPRQvY_sSe=s64","userId":"13448740953613370666"}}},"source":["# 初期設定\n","# Setup seeds\n","torch.manual_seed(1234)\n","np.random.seed(1234)\n","random.seed(1234)"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ejh1Rqxm5Dko"},"source":["# DataLoader作成"]},{"cell_type":"code","metadata":{"id":"1lKxvOS65Dko"},"source":["from utils.dataloader import make_datapath_list, DataTransform, VOCDataset\n","\n","# ファイルパスリスト作成\n","rootpath = \"./../data/VOCdevkit/VOC2012/\"\n","train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(\n","    rootpath=rootpath)\n","\n","# Dataset作成\n","# (RGB)の色の平均値と標準偏差\n","color_mean = (0.485, 0.456, 0.406)\n","color_std = (0.229, 0.224, 0.225)\n","\n","train_dataset = VOCDataset(train_img_list, train_anno_list, phase=\"train\", transform=DataTransform(\n","    input_size=475, color_mean=color_mean, color_std=color_std))\n","\n","val_dataset = VOCDataset(val_img_list, val_anno_list, phase=\"val\", transform=DataTransform(\n","    input_size=475, color_mean=color_mean, color_std=color_std))\n","\n","# DataLoader作成\n","batch_size = 8\n","\n","train_dataloader = data.DataLoader(\n","    train_dataset, batch_size=batch_size, shuffle=True)\n","\n","val_dataloader = data.DataLoader(\n","    val_dataset, batch_size=batch_size, shuffle=False)\n","\n","# 辞書型変数にまとめる\n","dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dEAUQA9q5Dkr"},"source":["# ネットワークモデル作成"]},{"cell_type":"code","metadata":{"id":"h8AkC5NH5Dkr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612939912601,"user_tz":-540,"elapsed":12192,"user":{"displayName":"Operational Amplifier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3etudnjCRnCXOZeYBsRUFbwA5_hCPRQvY_sSe=s64","userId":"13448740953613370666"}},"outputId":"398ad333-d830-48d2-f0b1-204a83de6442"},"source":["from utils.pspnet import PSPNet\n","\n","# ファインチューニングでPSPNetを作成\n","# ADE20Kデータセットの学習済みモデルを使用、ADE20Kはクラス数が150です\n","net = PSPNet(n_classes=150)\n","\n","# ADE20K学習済みパラメータをロード\n","state_dict = torch.load(\"./weights/pspnet50_ADE20K.pth\")\n","net.load_state_dict(state_dict)\n","\n","# 分類用の畳み込み層を、出力数21のものにつけかえる\n","n_classes = 21\n","net.decode_feature.classification = nn.Conv2d(\n","    in_channels=512, out_channels=n_classes, kernel_size=1, stride=1, padding=0)\n","\n","net.aux.classification = nn.Conv2d(\n","    in_channels=256, out_channels=n_classes, kernel_size=1, stride=1, padding=0)\n","\n","# 付け替えた畳み込み層を初期化する。活性化関数がシグモイド関数なのでXavierを使用する。\n","\n","\n","def weights_init(m):\n","    if isinstance(m, nn.Conv2d):\n","        nn.init.xavier_normal_(m.weight.data)\n","        if m.bias is not None:  # バイアス項がある場合\n","            nn.init.constant_(m.bias, 0.0)\n","\n","\n","net.decode_feature.classification.apply(weights_init)\n","net.aux.classification.apply(weights_init)\n","\n","\n","print('ネットワーク設定完了：学習済みの重みをロードしました')\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["ネットワーク設定完了：学習済みの重みをロードしました\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gXuKq8VP5Dku","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612939912602,"user_tz":-540,"elapsed":12185,"user":{"displayName":"Operational Amplifier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3etudnjCRnCXOZeYBsRUFbwA5_hCPRQvY_sSe=s64","userId":"13448740953613370666"}},"outputId":"e674359f-05c6-4b47-a953-03bf3330ccc9"},"source":["net"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PSPNet(\n","  (feature_conv): FeatureMap_convolution(\n","    (cbnr_1): conv2DBatchNormRelu(\n","      (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (cbnr_2): conv2DBatchNormRelu(\n","      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (cbnr_3): conv2DBatchNormRelu(\n","      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  )\n","  (feature_res_1): ResidualBlockPSP(\n","    (block1): bottleNeckPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (cb_residual): conv2DBatchNorm(\n","        (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (block2): bottleNeckIdentifyPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (block3): bottleNeckIdentifyPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (feature_res_2): ResidualBlockPSP(\n","    (block1): bottleNeckPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (cb_residual): conv2DBatchNorm(\n","        (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (block2): bottleNeckIdentifyPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (block3): bottleNeckIdentifyPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (block4): bottleNeckIdentifyPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (feature_dilated_res_1): ResidualBlockPSP(\n","    (block1): bottleNeckPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (cb_residual): conv2DBatchNorm(\n","        (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (block2): bottleNeckIdentifyPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (block3): bottleNeckIdentifyPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (block4): bottleNeckIdentifyPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (block5): bottleNeckIdentifyPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (block6): bottleNeckIdentifyPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (feature_dilated_res_2): ResidualBlockPSP(\n","    (block1): bottleNeckPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n","        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (cb_residual): conv2DBatchNorm(\n","        (conv): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (block2): bottleNeckIdentifyPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n","        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (block3): bottleNeckIdentifyPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n","        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (pyramid_pooling): PyramidPooling(\n","    (avpool_1): AdaptiveAvgPool2d(output_size=6)\n","    (cbr_1): conv2DBatchNormRelu(\n","      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (avpool_2): AdaptiveAvgPool2d(output_size=3)\n","    (cbr_2): conv2DBatchNormRelu(\n","      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (avpool_3): AdaptiveAvgPool2d(output_size=2)\n","    (cbr_3): conv2DBatchNormRelu(\n","      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (avpool_4): AdaptiveAvgPool2d(output_size=1)\n","    (cbr_4): conv2DBatchNormRelu(\n","      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (decode_feature): DecodePSPFeature(\n","    (cbr): conv2DBatchNormRelu(\n","      (conv): Conv2d(4096, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (dropout): Dropout2d(p=0.1, inplace=False)\n","    (classification): Conv2d(512, 21, kernel_size=(1, 1), stride=(1, 1))\n","  )\n","  (aux): AuxiliaryPSPlayers(\n","    (cbr): conv2DBatchNormRelu(\n","      (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (dropout): Dropout2d(p=0.1, inplace=False)\n","    (classification): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"t5bYr52Z5Dkw"},"source":["# 損失関数を定義"]},{"cell_type":"code","metadata":{"id":"C0Y6_cZh5Dkx"},"source":["# 損失関数の設定\n","class PSPLoss(nn.Module):\n","    \"\"\"PSPNetの損失関数のクラスです。\"\"\"\n","\n","    def __init__(self, aux_weight=0.4):\n","        super(PSPLoss, self).__init__()\n","        self.aux_weight = aux_weight  # aux_lossの重み\n","\n","    def forward(self, outputs, targets):\n","        \"\"\"\n","        損失関数の計算。\n","\n","        Parameters\n","        ----------\n","        outputs : PSPNetの出力(tuple)\n","            (output=torch.Size([num_batch, 21, 475, 475]), output_aux=torch.Size([num_batch, 21, 475, 475]))。\n","\n","        targets : [num_batch, 475, 475]\n","            正解のアノテーション情報\n","\n","        Returns\n","        -------\n","        loss : テンソル\n","            損失の値\n","        \"\"\"\n","\n","        loss = F.cross_entropy(outputs[0], targets, reduction='mean')\n","        loss_aux = F.cross_entropy(outputs[1], targets, reduction='mean')\n","\n","        return loss+self.aux_weight*loss_aux\n","\n","\n","criterion = PSPLoss(aux_weight=0.4)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gevOccLt5Dkz"},"source":["# 最適化手法を設定"]},{"cell_type":"code","metadata":{"id":"1HQuH4465Dk0"},"source":["# ファインチューニングなので、学習率は小さく\n","optimizer = optim.SGD([\n","    {'params': net.feature_conv.parameters(), 'lr': 1e-3},\n","    {'params': net.feature_res_1.parameters(), 'lr': 1e-3},\n","    {'params': net.feature_res_2.parameters(), 'lr': 1e-3},\n","    {'params': net.feature_dilated_res_1.parameters(), 'lr': 1e-3},\n","    {'params': net.feature_dilated_res_2.parameters(), 'lr': 1e-3},\n","    {'params': net.pyramid_pooling.parameters(), 'lr': 1e-3},\n","    {'params': net.decode_feature.parameters(), 'lr': 1e-2},\n","    {'params': net.aux.parameters(), 'lr': 1e-2},\n","], momentum=0.9, weight_decay=0.0001)\n","\n","\n","# スケジューラーの設定\n","def lambda_epoch(epoch):\n","    max_epoch = 30\n","    return math.pow((1-epoch/max_epoch), 0.9)\n","\n","\n","scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_epoch)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X0C1CqUP5Dk3"},"source":["# 学習・検証を実施する"]},{"cell_type":"code","metadata":{"id":"QDo8kP3r5Dk3"},"source":["# モデルを学習させる関数を作成\n","\n","\n","def train_model(net, dataloaders_dict, criterion, scheduler, optimizer, num_epochs):\n","\n","    # GPUが使えるかを確認\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    print(\"使用デバイス：\", device)\n","\n","    # ネットワークをGPUへ\n","    net.to(device)\n","\n","    # ネットワークがある程度固定であれば、高速化させる\n","    torch.backends.cudnn.benchmark = True\n","\n","    # 画像の枚数\n","    num_train_imgs = len(dataloaders_dict[\"train\"].dataset)\n","    num_val_imgs = len(dataloaders_dict[\"val\"].dataset)\n","    batch_size = dataloaders_dict[\"train\"].batch_size\n","\n","    # イテレーションカウンタをセット\n","    iteration = 1\n","    logs = []\n","\n","    # multiple minibatch\n","    batch_multiplier = 3\n","\n","    # epochのループ\n","    for epoch in range(num_epochs):\n","\n","        # 開始時刻を保存\n","        t_epoch_start = time.time()\n","        t_iter_start = time.time()\n","        epoch_train_loss = 0.0  # epochの損失和\n","        epoch_val_loss = 0.0  # epochの損失和\n","\n","        print('-------------')\n","        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n","        print('-------------')\n","\n","        # epochごとの訓練と検証のループ\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                net.train()  # モデルを訓練モードに\n","                scheduler.step()  # 最適化schedulerの更新\n","                optimizer.zero_grad()\n","                print('（train）')\n","\n","            else:\n","                if((epoch+1) % 5 == 0):\n","                    net.eval()   # モデルを検証モードに\n","                    print('-------------')\n","                    print('（val）')\n","                else:\n","                    # 検証は5回に1回だけ行う\n","                    continue\n","\n","            # データローダーからminibatchずつ取り出すループ\n","            count = 0  # multiple minibatch\n","            for imges, anno_class_imges in dataloaders_dict[phase]:\n","                # ミニバッチがサイズが1だと、バッチノーマライゼーションでエラーになるのでさける\n","                if imges.size()[0] == 1:\n","                    continue\n","\n","                # GPUが使えるならGPUにデータを送る\n","                imges = imges.to(device)\n","                anno_class_imges = anno_class_imges.to(device)\n","\n","                \n","                # multiple minibatchでのパラメータの更新\n","                if (phase == 'train') and (count == 0):\n","                    optimizer.step()\n","                    optimizer.zero_grad()\n","                    count = batch_multiplier\n","\n","                # 順伝搬（forward）計算\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = net(imges)\n","                    loss = criterion(\n","                        outputs, anno_class_imges.long()) / batch_multiplier\n","\n","                    # 訓練時はバックプロパゲーション\n","                    if phase == 'train':\n","                        loss.backward()  # 勾配の計算\n","                        count -= 1  # multiple minibatch\n","\n","                        if (iteration % 10 == 0):  # 10iterに1度、lossを表示\n","                            t_iter_finish = time.time()\n","                            duration = t_iter_finish - t_iter_start\n","                            print('イテレーション {} || Loss: {:.4f} || 10iter: {:.4f} sec.'.format(\n","                                iteration, loss.item()/batch_size*batch_multiplier, duration))\n","                            t_iter_start = time.time()\n","\n","                        epoch_train_loss += loss.item() * batch_multiplier\n","                        iteration += 1\n","\n","                    # 検証時\n","                    else:\n","                        epoch_val_loss += loss.item() * batch_multiplier\n","\n","        # epochのphaseごとのlossと正解率\n","        t_epoch_finish = time.time()\n","        print('-------------')\n","        print('epoch {} || Epoch_TRAIN_Loss:{:.4f} ||Epoch_VAL_Loss:{:.4f}'.format(\n","            epoch+1, epoch_train_loss/num_train_imgs, epoch_val_loss/num_val_imgs))\n","        print('timer:  {:.4f} sec.'.format(t_epoch_finish - t_epoch_start))\n","        t_epoch_start = time.time()\n","\n","        # ログを保存\n","        log_epoch = {'epoch': epoch+1, 'train_loss': epoch_train_loss /\n","                     num_train_imgs, 'val_loss': epoch_val_loss/num_val_imgs}\n","        logs.append(log_epoch)\n","        df = pd.DataFrame(logs)\n","        df.to_csv(\"log_output.csv\")\n","\n","    # 最後のネットワークを保存する\n","    torch.save(net.state_dict(), 'weights/pspnet50_' +\n","               str(epoch+1) + '.pth')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1XEy-KBb5Dk5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612955213362,"user_tz":-540,"elapsed":4119191,"user":{"displayName":"Operational Amplifier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3etudnjCRnCXOZeYBsRUFbwA5_hCPRQvY_sSe=s64","userId":"13448740953613370666"}},"outputId":"1f1f26ad-161a-433d-fa9c-8672981d937d"},"source":["# 学習・検証を実行する\n","num_epochs = 30\n","train_model(net, dataloaders_dict, criterion, scheduler, optimizer, num_epochs=num_epochs)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["使用デバイス： cuda:0\n","-------------\n","Epoch 1/30\n","-------------\n","（train）\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["イテレーション 10 || Loss: 0.3948 || 10iter: 151.1945 sec.\n","イテレーション 20 || Loss: 0.4554 || 10iter: 58.4763 sec.\n","イテレーション 30 || Loss: 0.1547 || 10iter: 57.4963 sec.\n","イテレーション 40 || Loss: 0.1613 || 10iter: 58.9038 sec.\n","イテレーション 50 || Loss: 0.1599 || 10iter: 57.7180 sec.\n","イテレーション 60 || Loss: 0.1131 || 10iter: 58.6193 sec.\n","イテレーション 70 || Loss: 0.1810 || 10iter: 59.0251 sec.\n","イテレーション 80 || Loss: 0.1551 || 10iter: 60.1814 sec.\n","イテレーション 90 || Loss: 0.1429 || 10iter: 59.1747 sec.\n","イテレーション 100 || Loss: 0.1206 || 10iter: 58.6838 sec.\n","イテレーション 110 || Loss: 0.0485 || 10iter: 59.4778 sec.\n","イテレーション 120 || Loss: 0.1305 || 10iter: 57.4945 sec.\n","イテレーション 130 || Loss: 0.0973 || 10iter: 57.9425 sec.\n","イテレーション 140 || Loss: 0.1000 || 10iter: 58.4011 sec.\n","イテレーション 150 || Loss: 0.1203 || 10iter: 59.1660 sec.\n","イテレーション 160 || Loss: 0.1549 || 10iter: 58.3563 sec.\n","イテレーション 170 || Loss: 0.1152 || 10iter: 57.4308 sec.\n","イテレーション 180 || Loss: 0.0902 || 10iter: 56.9639 sec.\n","-------------\n","epoch 1 || Epoch_TRAIN_Loss:0.1842 ||Epoch_VAL_Loss:0.0000\n","timer:  1200.5669 sec.\n","-------------\n","Epoch 2/30\n","-------------\n","（train）\n","イテレーション 190 || Loss: 0.0785 || 10iter: 14.7853 sec.\n","イテレーション 200 || Loss: 0.1282 || 10iter: 21.8498 sec.\n","イテレーション 210 || Loss: 0.0711 || 10iter: 21.5363 sec.\n","イテレーション 220 || Loss: 0.1103 || 10iter: 21.7650 sec.\n","イテレーション 230 || Loss: 0.1361 || 10iter: 21.7287 sec.\n","イテレーション 240 || Loss: 0.0919 || 10iter: 21.6703 sec.\n","イテレーション 250 || Loss: 0.1015 || 10iter: 21.6968 sec.\n","イテレーション 260 || Loss: 0.0863 || 10iter: 21.6966 sec.\n","イテレーション 270 || Loss: 0.0899 || 10iter: 21.7543 sec.\n","イテレーション 280 || Loss: 0.0919 || 10iter: 21.7280 sec.\n","イテレーション 290 || Loss: 0.0553 || 10iter: 21.7542 sec.\n","イテレーション 300 || Loss: 0.0541 || 10iter: 21.7135 sec.\n","イテレーション 310 || Loss: 0.1145 || 10iter: 21.6787 sec.\n","イテレーション 320 || Loss: 0.0785 || 10iter: 21.7454 sec.\n","イテレーション 330 || Loss: 0.0838 || 10iter: 21.7491 sec.\n","イテレーション 340 || Loss: 0.0790 || 10iter: 21.7018 sec.\n","イテレーション 350 || Loss: 0.1222 || 10iter: 21.7293 sec.\n","イテレーション 360 || Loss: 0.0466 || 10iter: 21.7325 sec.\n","-------------\n","epoch 2 || Epoch_TRAIN_Loss:0.0911 ||Epoch_VAL_Loss:0.0000\n","timer:  435.3893 sec.\n","-------------\n","Epoch 3/30\n","-------------\n","（train）\n","イテレーション 370 || Loss: 0.0655 || 10iter: 7.4412 sec.\n","イテレーション 380 || Loss: 0.0785 || 10iter: 21.6953 sec.\n","イテレーション 390 || Loss: 0.0997 || 10iter: 21.7155 sec.\n","イテレーション 400 || Loss: 0.1010 || 10iter: 21.6799 sec.\n","イテレーション 410 || Loss: 0.1059 || 10iter: 21.7347 sec.\n","イテレーション 420 || Loss: 0.0667 || 10iter: 21.6803 sec.\n","イテレーション 430 || Loss: 0.0843 || 10iter: 21.7885 sec.\n","イテレーション 440 || Loss: 0.0863 || 10iter: 21.6920 sec.\n","イテレーション 450 || Loss: 0.0638 || 10iter: 21.7182 sec.\n","イテレーション 460 || Loss: 0.0578 || 10iter: 21.7180 sec.\n","イテレーション 470 || Loss: 0.0684 || 10iter: 21.7339 sec.\n","イテレーション 480 || Loss: 0.0839 || 10iter: 21.7962 sec.\n","イテレーション 490 || Loss: 0.0614 || 10iter: 21.7086 sec.\n","イテレーション 500 || Loss: 0.0865 || 10iter: 21.6462 sec.\n","イテレーション 510 || Loss: 0.0882 || 10iter: 21.6505 sec.\n","イテレーション 520 || Loss: 0.0643 || 10iter: 21.7370 sec.\n","イテレーション 530 || Loss: 0.0749 || 10iter: 21.7412 sec.\n","イテレーション 540 || Loss: 0.0534 || 10iter: 21.6793 sec.\n","-------------\n","epoch 3 || Epoch_TRAIN_Loss:0.0805 ||Epoch_VAL_Loss:0.0000\n","timer:  435.0212 sec.\n","-------------\n","Epoch 4/30\n","-------------\n","（train）\n","イテレーション 550 || Loss: 0.0555 || 10iter: 0.3344 sec.\n","イテレーション 560 || Loss: 0.0782 || 10iter: 21.7136 sec.\n","イテレーション 570 || Loss: 0.0523 || 10iter: 21.6685 sec.\n","イテレーション 580 || Loss: 0.0582 || 10iter: 21.6948 sec.\n","イテレーション 590 || Loss: 0.0742 || 10iter: 21.7203 sec.\n","イテレーション 600 || Loss: 0.1032 || 10iter: 21.7224 sec.\n","イテレーション 610 || Loss: 0.0532 || 10iter: 21.7022 sec.\n","イテレーション 620 || Loss: 0.0648 || 10iter: 21.7162 sec.\n","イテレーション 630 || Loss: 0.1018 || 10iter: 21.7010 sec.\n","イテレーション 640 || Loss: 0.0638 || 10iter: 21.7022 sec.\n","イテレーション 650 || Loss: 0.0954 || 10iter: 21.6864 sec.\n","イテレーション 660 || Loss: 0.0560 || 10iter: 21.7989 sec.\n","イテレーション 670 || Loss: 0.0478 || 10iter: 21.6939 sec.\n","イテレーション 680 || Loss: 0.0798 || 10iter: 21.6738 sec.\n","イテレーション 690 || Loss: 0.0891 || 10iter: 21.6903 sec.\n","イテレーション 700 || Loss: 0.0746 || 10iter: 21.6665 sec.\n","イテレーション 710 || Loss: 0.0445 || 10iter: 21.7030 sec.\n","イテレーション 720 || Loss: 0.0584 || 10iter: 21.6796 sec.\n","イテレーション 730 || Loss: 0.0847 || 10iter: 21.6720 sec.\n","-------------\n","epoch 4 || Epoch_TRAIN_Loss:0.0697 ||Epoch_VAL_Loss:0.0000\n","timer:  434.8930 sec.\n","-------------\n","Epoch 5/30\n","-------------\n","（train）\n","イテレーション 740 || Loss: 0.0751 || 10iter: 16.9572 sec.\n","イテレーション 750 || Loss: 0.0944 || 10iter: 21.7288 sec.\n","イテレーション 760 || Loss: 0.0591 || 10iter: 21.7084 sec.\n","イテレーション 770 || Loss: 0.0661 || 10iter: 21.6466 sec.\n","イテレーション 780 || Loss: 0.0582 || 10iter: 21.6292 sec.\n","イテレーション 790 || Loss: 0.0588 || 10iter: 21.6778 sec.\n","イテレーション 800 || Loss: 0.0775 || 10iter: 21.6458 sec.\n","イテレーション 810 || Loss: 0.0452 || 10iter: 21.6513 sec.\n","イテレーション 820 || Loss: 0.0621 || 10iter: 21.6414 sec.\n","イテレーション 830 || Loss: 0.0938 || 10iter: 21.6439 sec.\n","イテレーション 840 || Loss: 0.0956 || 10iter: 21.7832 sec.\n","イテレーション 850 || Loss: 0.0372 || 10iter: 21.6976 sec.\n","イテレーション 860 || Loss: 0.0549 || 10iter: 21.6358 sec.\n","イテレーション 870 || Loss: 0.0457 || 10iter: 21.7573 sec.\n","イテレーション 880 || Loss: 0.0444 || 10iter: 21.7446 sec.\n","イテレーション 890 || Loss: 0.0404 || 10iter: 21.6731 sec.\n","イテレーション 900 || Loss: 0.0394 || 10iter: 21.6744 sec.\n","イテレーション 910 || Loss: 0.0479 || 10iter: 21.7119 sec.\n","-------------\n","（val）\n","-------------\n","epoch 5 || Epoch_TRAIN_Loss:0.0636 ||Epoch_VAL_Loss:0.0798\n","timer:  1236.8538 sec.\n","-------------\n","Epoch 6/30\n","-------------\n","（train）\n","イテレーション 920 || Loss: 0.1000 || 10iter: 9.9328 sec.\n","イテレーション 930 || Loss: 0.0205 || 10iter: 21.9554 sec.\n","イテレーション 940 || Loss: 0.1264 || 10iter: 21.6501 sec.\n","イテレーション 950 || Loss: 0.0530 || 10iter: 21.6786 sec.\n","イテレーション 960 || Loss: 0.0518 || 10iter: 21.7834 sec.\n","イテレーション 970 || Loss: 0.0598 || 10iter: 21.7134 sec.\n","イテレーション 980 || Loss: 0.0540 || 10iter: 21.6991 sec.\n","イテレーション 990 || Loss: 0.0450 || 10iter: 21.6802 sec.\n","イテレーション 1000 || Loss: 0.0756 || 10iter: 21.7236 sec.\n","イテレーション 1010 || Loss: 0.0388 || 10iter: 21.6694 sec.\n","イテレーション 1020 || Loss: 0.0376 || 10iter: 21.6948 sec.\n","イテレーション 1030 || Loss: 0.0631 || 10iter: 21.6904 sec.\n","イテレーション 1040 || Loss: 0.0997 || 10iter: 21.6383 sec.\n","イテレーション 1050 || Loss: 0.0421 || 10iter: 21.7310 sec.\n","イテレーション 1060 || Loss: 0.0706 || 10iter: 21.7293 sec.\n","イテレーション 1070 || Loss: 0.1109 || 10iter: 21.7174 sec.\n","イテレーション 1080 || Loss: 0.1843 || 10iter: 21.7338 sec.\n","イテレーション 1090 || Loss: 0.0753 || 10iter: 21.6529 sec.\n","-------------\n","epoch 6 || Epoch_TRAIN_Loss:0.0624 ||Epoch_VAL_Loss:0.0000\n","timer:  435.1958 sec.\n","-------------\n","Epoch 7/30\n","-------------\n","（train）\n","イテレーション 1100 || Loss: 0.0506 || 10iter: 2.6841 sec.\n","イテレーション 1110 || Loss: 0.0395 || 10iter: 21.6766 sec.\n","イテレーション 1120 || Loss: 0.0416 || 10iter: 21.7078 sec.\n","イテレーション 1130 || Loss: 0.0872 || 10iter: 21.6792 sec.\n","イテレーション 1140 || Loss: 0.0915 || 10iter: 21.6549 sec.\n","イテレーション 1150 || Loss: 0.0377 || 10iter: 21.6607 sec.\n","イテレーション 1160 || Loss: 0.0654 || 10iter: 21.6698 sec.\n","イテレーション 1170 || Loss: 0.0524 || 10iter: 21.7159 sec.\n","イテレーション 1180 || Loss: 0.0493 || 10iter: 21.7299 sec.\n","イテレーション 1190 || Loss: 0.0489 || 10iter: 21.7066 sec.\n","イテレーション 1200 || Loss: 0.1236 || 10iter: 21.6645 sec.\n","イテレーション 1210 || Loss: 0.0452 || 10iter: 21.6764 sec.\n","イテレーション 1220 || Loss: 0.0421 || 10iter: 21.7121 sec.\n","イテレーション 1230 || Loss: 0.0936 || 10iter: 21.7264 sec.\n","イテレーション 1240 || Loss: 0.0439 || 10iter: 21.7257 sec.\n","イテレーション 1250 || Loss: 0.0657 || 10iter: 21.7347 sec.\n","イテレーション 1260 || Loss: 0.0492 || 10iter: 21.6758 sec.\n","イテレーション 1270 || Loss: 0.0374 || 10iter: 21.6945 sec.\n","イテレーション 1280 || Loss: 0.0492 || 10iter: 21.7760 sec.\n","-------------\n","epoch 7 || Epoch_TRAIN_Loss:0.0578 ||Epoch_VAL_Loss:0.0000\n","timer:  434.8453 sec.\n","-------------\n","Epoch 8/30\n","-------------\n","（train）\n","イテレーション 1290 || Loss: 0.0625 || 10iter: 19.3137 sec.\n","イテレーション 1300 || Loss: 0.0260 || 10iter: 21.6593 sec.\n","イテレーション 1310 || Loss: 0.0331 || 10iter: 21.6797 sec.\n","イテレーション 1320 || Loss: 0.0977 || 10iter: 21.7091 sec.\n","イテレーション 1330 || Loss: 0.0532 || 10iter: 21.7351 sec.\n","イテレーション 1340 || Loss: 0.0694 || 10iter: 21.6921 sec.\n","イテレーション 1350 || Loss: 0.0864 || 10iter: 21.6733 sec.\n","イテレーション 1360 || Loss: 0.0513 || 10iter: 21.6074 sec.\n","イテレーション 1370 || Loss: 0.0523 || 10iter: 21.6893 sec.\n","イテレーション 1380 || Loss: 0.0617 || 10iter: 21.7197 sec.\n","イテレーション 1390 || Loss: 0.0299 || 10iter: 21.6917 sec.\n","イテレーション 1400 || Loss: 0.0649 || 10iter: 21.6691 sec.\n","イテレーション 1410 || Loss: 0.0517 || 10iter: 21.6740 sec.\n","イテレーション 1420 || Loss: 0.0565 || 10iter: 21.7703 sec.\n","イテレーション 1430 || Loss: 0.0546 || 10iter: 21.6558 sec.\n","イテレーション 1440 || Loss: 0.0581 || 10iter: 21.6707 sec.\n","イテレーション 1450 || Loss: 0.0368 || 10iter: 21.7823 sec.\n","イテレーション 1460 || Loss: 0.0605 || 10iter: 21.7159 sec.\n","-------------\n","epoch 8 || Epoch_TRAIN_Loss:0.0565 ||Epoch_VAL_Loss:0.0000\n","timer:  434.7324 sec.\n","-------------\n","Epoch 9/30\n","-------------\n","（train）\n","イテレーション 1470 || Loss: 0.0625 || 10iter: 12.1958 sec.\n","イテレーション 1480 || Loss: 0.0356 || 10iter: 21.6633 sec.\n","イテレーション 1490 || Loss: 0.0820 || 10iter: 21.7218 sec.\n","イテレーション 1500 || Loss: 0.0701 || 10iter: 21.6489 sec.\n","イテレーション 1510 || Loss: 0.0462 || 10iter: 21.7165 sec.\n","イテレーション 1520 || Loss: 0.0342 || 10iter: 21.6953 sec.\n","イテレーション 1530 || Loss: 0.0488 || 10iter: 21.6715 sec.\n","イテレーション 1540 || Loss: 0.0242 || 10iter: 21.7292 sec.\n","イテレーション 1550 || Loss: 0.0354 || 10iter: 21.6969 sec.\n","イテレーション 1560 || Loss: 0.0492 || 10iter: 21.6649 sec.\n","イテレーション 1570 || Loss: 0.0467 || 10iter: 21.6907 sec.\n","イテレーション 1580 || Loss: 0.0548 || 10iter: 21.7079 sec.\n","イテレーション 1590 || Loss: 0.0504 || 10iter: 21.7055 sec.\n","イテレーション 1600 || Loss: 0.0552 || 10iter: 21.6756 sec.\n","イテレーション 1610 || Loss: 0.0401 || 10iter: 21.6430 sec.\n","イテレーション 1620 || Loss: 0.0787 || 10iter: 21.6711 sec.\n","イテレーション 1630 || Loss: 0.0442 || 10iter: 21.6243 sec.\n","イテレーション 1640 || Loss: 0.0557 || 10iter: 21.7215 sec.\n","-------------\n","epoch 9 || Epoch_TRAIN_Loss:0.0557 ||Epoch_VAL_Loss:0.0000\n","timer:  434.5926 sec.\n","-------------\n","Epoch 10/30\n","-------------\n","（train）\n","イテレーション 1650 || Loss: 0.0358 || 10iter: 5.0571 sec.\n","イテレーション 1660 || Loss: 0.0577 || 10iter: 21.7484 sec.\n","イテレーション 1670 || Loss: 0.0665 || 10iter: 21.6563 sec.\n","イテレーション 1680 || Loss: 0.0447 || 10iter: 21.6360 sec.\n","イテレーション 1690 || Loss: 0.0485 || 10iter: 21.6986 sec.\n","イテレーション 1700 || Loss: 0.0563 || 10iter: 21.6045 sec.\n","イテレーション 1710 || Loss: 0.0631 || 10iter: 21.6820 sec.\n","イテレーション 1720 || Loss: 0.0597 || 10iter: 21.6983 sec.\n","イテレーション 1730 || Loss: 0.0412 || 10iter: 21.6964 sec.\n","イテレーション 1740 || Loss: 0.0308 || 10iter: 21.7100 sec.\n","イテレーション 1750 || Loss: 0.0350 || 10iter: 21.7122 sec.\n","イテレーション 1760 || Loss: 0.0498 || 10iter: 21.7315 sec.\n","イテレーション 1770 || Loss: 0.0531 || 10iter: 21.6440 sec.\n","イテレーション 1780 || Loss: 0.0342 || 10iter: 21.6419 sec.\n","イテレーション 1790 || Loss: 0.0331 || 10iter: 21.6596 sec.\n","イテレーション 1800 || Loss: 0.0361 || 10iter: 21.6370 sec.\n","イテレーション 1810 || Loss: 0.0599 || 10iter: 21.6824 sec.\n","イテレーション 1820 || Loss: 0.0589 || 10iter: 21.6315 sec.\n","イテレーション 1830 || Loss: 0.0702 || 10iter: 21.6949 sec.\n","-------------\n","（val）\n","-------------\n","epoch 10 || Epoch_TRAIN_Loss:0.0517 ||Epoch_VAL_Loss:0.0748\n","timer:  569.9679 sec.\n","-------------\n","Epoch 11/30\n","-------------\n","（train）\n","イテレーション 1840 || Loss: 0.0396 || 10iter: 21.7059 sec.\n","イテレーション 1850 || Loss: 0.0667 || 10iter: 21.6773 sec.\n","イテレーション 1860 || Loss: 0.0654 || 10iter: 21.6562 sec.\n","イテレーション 1870 || Loss: 0.0322 || 10iter: 21.7209 sec.\n","イテレーション 1880 || Loss: 0.0458 || 10iter: 21.6702 sec.\n","イテレーション 1890 || Loss: 0.0309 || 10iter: 21.6505 sec.\n","イテレーション 1900 || Loss: 0.0493 || 10iter: 21.6438 sec.\n","イテレーション 1910 || Loss: 0.0495 || 10iter: 21.7580 sec.\n","イテレーション 1920 || Loss: 0.0605 || 10iter: 21.7401 sec.\n","イテレーション 1930 || Loss: 0.0456 || 10iter: 21.6047 sec.\n","イテレーション 1940 || Loss: 0.0513 || 10iter: 21.6536 sec.\n","イテレーション 1950 || Loss: 0.0697 || 10iter: 21.6767 sec.\n","イテレーション 1960 || Loss: 0.0524 || 10iter: 21.7561 sec.\n","イテレーション 1970 || Loss: 0.0621 || 10iter: 21.7155 sec.\n","イテレーション 1980 || Loss: 0.0415 || 10iter: 21.6628 sec.\n","イテレーション 1990 || Loss: 0.0261 || 10iter: 21.6282 sec.\n","イテレーション 2000 || Loss: 0.0375 || 10iter: 21.6968 sec.\n","イテレーション 2010 || Loss: 0.0598 || 10iter: 21.7321 sec.\n","-------------\n","epoch 11 || Epoch_TRAIN_Loss:0.0500 ||Epoch_VAL_Loss:0.0000\n","timer:  434.5355 sec.\n","-------------\n","Epoch 12/30\n","-------------\n","（train）\n","イテレーション 2020 || Loss: 0.0350 || 10iter: 14.5183 sec.\n","イテレーション 2030 || Loss: 0.0517 || 10iter: 21.6654 sec.\n","イテレーション 2040 || Loss: 0.0357 || 10iter: 21.6889 sec.\n","イテレーション 2050 || Loss: 0.0616 || 10iter: 21.7445 sec.\n","イテレーション 2060 || Loss: 0.0483 || 10iter: 21.6499 sec.\n","イテレーション 2070 || Loss: 0.0281 || 10iter: 21.6631 sec.\n","イテレーション 2080 || Loss: 0.0490 || 10iter: 21.6742 sec.\n","イテレーション 2090 || Loss: 0.0855 || 10iter: 21.7038 sec.\n","イテレーション 2100 || Loss: 0.0325 || 10iter: 21.6308 sec.\n","イテレーション 2110 || Loss: 0.0326 || 10iter: 21.6915 sec.\n","イテレーション 2120 || Loss: 0.0409 || 10iter: 21.6681 sec.\n","イテレーション 2130 || Loss: 0.0435 || 10iter: 21.6647 sec.\n","イテレーション 2140 || Loss: 0.0482 || 10iter: 21.7146 sec.\n","イテレーション 2150 || Loss: 0.0522 || 10iter: 21.6817 sec.\n","イテレーション 2160 || Loss: 0.0521 || 10iter: 21.6102 sec.\n","イテレーション 2170 || Loss: 0.0390 || 10iter: 21.6852 sec.\n","イテレーション 2180 || Loss: 0.0550 || 10iter: 21.6974 sec.\n","イテレーション 2190 || Loss: 0.0694 || 10iter: 21.6759 sec.\n","-------------\n","epoch 12 || Epoch_TRAIN_Loss:0.0466 ||Epoch_VAL_Loss:0.0000\n","timer:  434.3952 sec.\n","-------------\n","Epoch 13/30\n","-------------\n","（train）\n","イテレーション 2200 || Loss: 0.0197 || 10iter: 7.4516 sec.\n","イテレーション 2210 || Loss: 0.0360 || 10iter: 21.6380 sec.\n","イテレーション 2220 || Loss: 0.0372 || 10iter: 21.6434 sec.\n","イテレーション 2230 || Loss: 0.0699 || 10iter: 21.7235 sec.\n","イテレーション 2240 || Loss: 0.0515 || 10iter: 21.7576 sec.\n","イテレーション 2250 || Loss: 0.0305 || 10iter: 21.6679 sec.\n","イテレーション 2260 || Loss: 0.0655 || 10iter: 21.6603 sec.\n","イテレーション 2270 || Loss: 0.0675 || 10iter: 21.6706 sec.\n","イテレーション 2280 || Loss: 0.0269 || 10iter: 21.7089 sec.\n","イテレーション 2290 || Loss: 0.0364 || 10iter: 21.6661 sec.\n","イテレーション 2300 || Loss: 0.0555 || 10iter: 21.6386 sec.\n","イテレーション 2310 || Loss: 0.0334 || 10iter: 21.6787 sec.\n","イテレーション 2320 || Loss: 0.0324 || 10iter: 21.6977 sec.\n","イテレーション 2330 || Loss: 0.0369 || 10iter: 21.6330 sec.\n","イテレーション 2340 || Loss: 0.0481 || 10iter: 21.6756 sec.\n","イテレーション 2350 || Loss: 0.0280 || 10iter: 21.7340 sec.\n","イテレーション 2360 || Loss: 0.0424 || 10iter: 21.7265 sec.\n","イテレーション 2370 || Loss: 0.0646 || 10iter: 21.6581 sec.\n","-------------\n","epoch 13 || Epoch_TRAIN_Loss:0.0470 ||Epoch_VAL_Loss:0.0000\n","timer:  434.4864 sec.\n","-------------\n","Epoch 14/30\n","-------------\n","（train）\n","イテレーション 2380 || Loss: 0.0340 || 10iter: 0.3261 sec.\n","イテレーション 2390 || Loss: 0.0374 || 10iter: 21.6874 sec.\n","イテレーション 2400 || Loss: 0.0354 || 10iter: 21.6471 sec.\n","イテレーション 2410 || Loss: 0.0459 || 10iter: 21.7179 sec.\n","イテレーション 2420 || Loss: 0.0318 || 10iter: 21.7466 sec.\n","イテレーション 2430 || Loss: 0.0283 || 10iter: 21.6349 sec.\n","イテレーション 2440 || Loss: 0.0430 || 10iter: 21.8140 sec.\n","イテレーション 2450 || Loss: 0.0424 || 10iter: 21.6366 sec.\n","イテレーション 2460 || Loss: 0.0480 || 10iter: 21.7285 sec.\n","イテレーション 2470 || Loss: 0.0356 || 10iter: 21.6972 sec.\n","イテレーション 2480 || Loss: 0.0369 || 10iter: 21.6339 sec.\n","イテレーション 2490 || Loss: 0.0663 || 10iter: 21.6425 sec.\n","イテレーション 2500 || Loss: 0.0349 || 10iter: 21.6708 sec.\n","イテレーション 2510 || Loss: 0.0403 || 10iter: 21.7259 sec.\n","イテレーション 2520 || Loss: 0.0719 || 10iter: 21.7395 sec.\n","イテレーション 2530 || Loss: 0.0686 || 10iter: 21.6719 sec.\n","イテレーション 2540 || Loss: 0.0776 || 10iter: 21.7262 sec.\n","イテレーション 2550 || Loss: 0.0936 || 10iter: 21.6829 sec.\n","イテレーション 2560 || Loss: 0.0338 || 10iter: 21.7099 sec.\n","-------------\n","epoch 14 || Epoch_TRAIN_Loss:0.0461 ||Epoch_VAL_Loss:0.0000\n","timer:  434.7932 sec.\n","-------------\n","Epoch 15/30\n","-------------\n","（train）\n","イテレーション 2570 || Loss: 0.0449 || 10iter: 16.9523 sec.\n","イテレーション 2580 || Loss: 0.0460 || 10iter: 21.6622 sec.\n","イテレーション 2590 || Loss: 0.0381 || 10iter: 21.7290 sec.\n","イテレーション 2600 || Loss: 0.0419 || 10iter: 21.6664 sec.\n","イテレーション 2610 || Loss: 0.0468 || 10iter: 21.6877 sec.\n","イテレーション 2620 || Loss: 0.0331 || 10iter: 21.6596 sec.\n","イテレーション 2630 || Loss: 0.0310 || 10iter: 21.6716 sec.\n","イテレーション 2640 || Loss: 0.0388 || 10iter: 21.6919 sec.\n","イテレーション 2650 || Loss: 0.0379 || 10iter: 21.6453 sec.\n","イテレーション 2660 || Loss: 0.0584 || 10iter: 21.7570 sec.\n","イテレーション 2670 || Loss: 0.0712 || 10iter: 21.6898 sec.\n","イテレーション 2680 || Loss: 0.0379 || 10iter: 21.6613 sec.\n","イテレーション 2690 || Loss: 0.0378 || 10iter: 21.6559 sec.\n","イテレーション 2700 || Loss: 0.0370 || 10iter: 21.6952 sec.\n","イテレーション 2710 || Loss: 0.0528 || 10iter: 21.7596 sec.\n","イテレーション 2720 || Loss: 0.0572 || 10iter: 21.6248 sec.\n","イテレーション 2730 || Loss: 0.0452 || 10iter: 21.6552 sec.\n","イテレーション 2740 || Loss: 0.0276 || 10iter: 21.6799 sec.\n","-------------\n","（val）\n","-------------\n","epoch 15 || Epoch_TRAIN_Loss:0.0460 ||Epoch_VAL_Loss:0.0717\n","timer:  569.9316 sec.\n","-------------\n","Epoch 16/30\n","-------------\n","（train）\n","イテレーション 2750 || Loss: 0.0423 || 10iter: 9.8052 sec.\n","イテレーション 2760 || Loss: 0.0447 || 10iter: 21.5981 sec.\n","イテレーション 2770 || Loss: 0.0442 || 10iter: 21.7018 sec.\n","イテレーション 2780 || Loss: 0.0464 || 10iter: 21.6767 sec.\n","イテレーション 2790 || Loss: 0.0520 || 10iter: 21.5521 sec.\n","イテレーション 2800 || Loss: 0.0645 || 10iter: 21.7534 sec.\n","イテレーション 2810 || Loss: 0.0346 || 10iter: 21.6452 sec.\n","イテレーション 2820 || Loss: 0.0402 || 10iter: 21.6252 sec.\n","イテレーション 2830 || Loss: 0.0669 || 10iter: 21.7214 sec.\n","イテレーション 2840 || Loss: 0.0499 || 10iter: 21.7122 sec.\n","イテレーション 2850 || Loss: 0.0707 || 10iter: 21.6356 sec.\n","イテレーション 2860 || Loss: 0.0523 || 10iter: 21.7095 sec.\n","イテレーション 2870 || Loss: 0.0574 || 10iter: 21.7358 sec.\n","イテレーション 2880 || Loss: 0.0477 || 10iter: 21.6610 sec.\n","イテレーション 2890 || Loss: 0.0359 || 10iter: 21.6998 sec.\n","イテレーション 2900 || Loss: 0.0412 || 10iter: 21.6952 sec.\n","イテレーション 2910 || Loss: 0.0457 || 10iter: 21.6628 sec.\n","イテレーション 2920 || Loss: 0.0659 || 10iter: 21.6856 sec.\n","-------------\n","epoch 16 || Epoch_TRAIN_Loss:0.0450 ||Epoch_VAL_Loss:0.0000\n","timer:  434.3623 sec.\n","-------------\n","Epoch 17/30\n","-------------\n","（train）\n","イテレーション 2930 || Loss: 0.0324 || 10iter: 2.6801 sec.\n","イテレーション 2940 || Loss: 0.0401 || 10iter: 21.6619 sec.\n","イテレーション 2950 || Loss: 0.0470 || 10iter: 21.7063 sec.\n","イテレーション 2960 || Loss: 0.0717 || 10iter: 21.6299 sec.\n","イテレーション 2970 || Loss: 0.0696 || 10iter: 21.5828 sec.\n","イテレーション 2980 || Loss: 0.0576 || 10iter: 21.6621 sec.\n","イテレーション 2990 || Loss: 0.0569 || 10iter: 21.6847 sec.\n","イテレーション 3000 || Loss: 0.0346 || 10iter: 21.7009 sec.\n","イテレーション 3010 || Loss: 0.0343 || 10iter: 21.6856 sec.\n","イテレーション 3020 || Loss: 0.0456 || 10iter: 21.6670 sec.\n","イテレーション 3030 || Loss: 0.0460 || 10iter: 21.6542 sec.\n","イテレーション 3040 || Loss: 0.0365 || 10iter: 21.7155 sec.\n","イテレーション 3050 || Loss: 0.0284 || 10iter: 21.6718 sec.\n","イテレーション 3060 || Loss: 0.0240 || 10iter: 21.7580 sec.\n","イテレーション 3070 || Loss: 0.0365 || 10iter: 21.6759 sec.\n","イテレーション 3080 || Loss: 0.0626 || 10iter: 21.6012 sec.\n","イテレーション 3090 || Loss: 0.0271 || 10iter: 21.6940 sec.\n","イテレーション 3100 || Loss: 0.0500 || 10iter: 21.5939 sec.\n","イテレーション 3110 || Loss: 0.0446 || 10iter: 21.7232 sec.\n","-------------\n","epoch 17 || Epoch_TRAIN_Loss:0.0437 ||Epoch_VAL_Loss:0.0000\n","timer:  434.3051 sec.\n","-------------\n","Epoch 18/30\n","-------------\n","（train）\n","イテレーション 3120 || Loss: 0.0375 || 10iter: 19.2831 sec.\n","イテレーション 3130 || Loss: 0.0294 || 10iter: 21.6828 sec.\n","イテレーション 3140 || Loss: 0.0309 || 10iter: 21.6793 sec.\n","イテレーション 3150 || Loss: 0.0370 || 10iter: 21.6226 sec.\n","イテレーション 3160 || Loss: 0.0575 || 10iter: 21.6338 sec.\n","イテレーション 3170 || Loss: 0.0347 || 10iter: 21.6293 sec.\n","イテレーション 3180 || Loss: 0.0310 || 10iter: 21.6139 sec.\n","イテレーション 3190 || Loss: 0.0306 || 10iter: 21.6674 sec.\n","イテレーション 3200 || Loss: 0.0592 || 10iter: 21.6641 sec.\n","イテレーション 3210 || Loss: 0.0445 || 10iter: 21.6557 sec.\n","イテレーション 3220 || Loss: 0.0857 || 10iter: 21.7199 sec.\n","イテレーション 3230 || Loss: 0.0415 || 10iter: 21.6410 sec.\n","イテレーション 3240 || Loss: 0.0588 || 10iter: 21.6673 sec.\n","イテレーション 3250 || Loss: 0.0570 || 10iter: 21.7242 sec.\n","イテレーション 3260 || Loss: 0.0515 || 10iter: 21.7179 sec.\n","イテレーション 3270 || Loss: 0.0266 || 10iter: 21.6849 sec.\n","イテレーション 3280 || Loss: 0.0286 || 10iter: 21.6842 sec.\n","イテレーション 3290 || Loss: 0.0288 || 10iter: 21.6636 sec.\n","-------------\n","epoch 18 || Epoch_TRAIN_Loss:0.0441 ||Epoch_VAL_Loss:0.0000\n","timer:  434.1376 sec.\n","-------------\n","Epoch 19/30\n","-------------\n","（train）\n","イテレーション 3300 || Loss: 0.0442 || 10iter: 12.2356 sec.\n","イテレーション 3310 || Loss: 0.0676 || 10iter: 21.6878 sec.\n","イテレーション 3320 || Loss: 0.0307 || 10iter: 21.6582 sec.\n","イテレーション 3330 || Loss: 0.0376 || 10iter: 21.6804 sec.\n","イテレーション 3340 || Loss: 0.0451 || 10iter: 21.7266 sec.\n","イテレーション 3350 || Loss: 0.0267 || 10iter: 21.6413 sec.\n","イテレーション 3360 || Loss: 0.0607 || 10iter: 21.6440 sec.\n","イテレーション 3370 || Loss: 0.0304 || 10iter: 21.6851 sec.\n","イテレーション 3380 || Loss: 0.0369 || 10iter: 21.7230 sec.\n","イテレーション 3390 || Loss: 0.0229 || 10iter: 21.6963 sec.\n","イテレーション 3400 || Loss: 0.0645 || 10iter: 21.6583 sec.\n","イテレーション 3410 || Loss: 0.0410 || 10iter: 21.6746 sec.\n","イテレーション 3420 || Loss: 0.0368 || 10iter: 21.6698 sec.\n","イテレーション 3430 || Loss: 0.0548 || 10iter: 21.7894 sec.\n","イテレーション 3440 || Loss: 0.0735 || 10iter: 21.6347 sec.\n","イテレーション 3450 || Loss: 0.0541 || 10iter: 21.6818 sec.\n","イテレーション 3460 || Loss: 0.0282 || 10iter: 21.6919 sec.\n","イテレーション 3470 || Loss: 0.0248 || 10iter: 21.6583 sec.\n","-------------\n","epoch 19 || Epoch_TRAIN_Loss:0.0437 ||Epoch_VAL_Loss:0.0000\n","timer:  434.5333 sec.\n","-------------\n","Epoch 20/30\n","-------------\n","（train）\n","イテレーション 3480 || Loss: 0.0404 || 10iter: 5.1099 sec.\n","イテレーション 3490 || Loss: 0.0300 || 10iter: 21.6480 sec.\n","イテレーション 3500 || Loss: 0.0438 || 10iter: 21.5587 sec.\n","イテレーション 3510 || Loss: 0.0283 || 10iter: 21.6369 sec.\n","イテレーション 3520 || Loss: 0.0323 || 10iter: 21.6884 sec.\n","イテレーション 3530 || Loss: 0.0254 || 10iter: 21.6752 sec.\n","イテレーション 3540 || Loss: 0.0430 || 10iter: 21.7270 sec.\n","イテレーション 3550 || Loss: 0.0444 || 10iter: 21.6346 sec.\n","イテレーション 3560 || Loss: 0.0591 || 10iter: 21.6695 sec.\n","イテレーション 3570 || Loss: 0.0535 || 10iter: 21.6415 sec.\n","イテレーション 3580 || Loss: 0.0398 || 10iter: 21.6586 sec.\n","イテレーション 3590 || Loss: 0.0408 || 10iter: 21.6807 sec.\n","イテレーション 3600 || Loss: 0.0424 || 10iter: 21.6933 sec.\n","イテレーション 3610 || Loss: 0.0350 || 10iter: 21.7263 sec.\n","イテレーション 3620 || Loss: 0.0404 || 10iter: 21.7011 sec.\n","イテレーション 3630 || Loss: 0.0308 || 10iter: 21.6799 sec.\n","イテレーション 3640 || Loss: 0.0398 || 10iter: 21.7581 sec.\n","イテレーション 3650 || Loss: 0.0579 || 10iter: 21.6136 sec.\n","イテレーション 3660 || Loss: 0.0431 || 10iter: 21.6448 sec.\n","-------------\n","（val）\n","-------------\n","epoch 20 || Epoch_TRAIN_Loss:0.0430 ||Epoch_VAL_Loss:0.0711\n","timer:  569.7296 sec.\n","-------------\n","Epoch 21/30\n","-------------\n","（train）\n","イテレーション 3670 || Loss: 0.0737 || 10iter: 21.6941 sec.\n","イテレーション 3680 || Loss: 0.0410 || 10iter: 21.7123 sec.\n","イテレーション 3690 || Loss: 0.0404 || 10iter: 21.6634 sec.\n","イテレーション 3700 || Loss: 0.0178 || 10iter: 21.6871 sec.\n","イテレーション 3710 || Loss: 0.0314 || 10iter: 21.7242 sec.\n","イテレーション 3720 || Loss: 0.0444 || 10iter: 21.6468 sec.\n","イテレーション 3730 || Loss: 0.0777 || 10iter: 21.6864 sec.\n","イテレーション 3740 || Loss: 0.0373 || 10iter: 21.6036 sec.\n","イテレーション 3750 || Loss: 0.0274 || 10iter: 21.7087 sec.\n","イテレーション 3760 || Loss: 0.0196 || 10iter: 21.6843 sec.\n","イテレーション 3770 || Loss: 0.0406 || 10iter: 21.6931 sec.\n","イテレーション 3780 || Loss: 0.0613 || 10iter: 21.7105 sec.\n","イテレーション 3790 || Loss: 0.0537 || 10iter: 21.6735 sec.\n","イテレーション 3800 || Loss: 0.0592 || 10iter: 21.6728 sec.\n","イテレーション 3810 || Loss: 0.0911 || 10iter: 21.7151 sec.\n","イテレーション 3820 || Loss: 0.0379 || 10iter: 21.7380 sec.\n","イテレーション 3830 || Loss: 0.0609 || 10iter: 21.7431 sec.\n","イテレーション 3840 || Loss: 0.0282 || 10iter: 21.7094 sec.\n","-------------\n","epoch 21 || Epoch_TRAIN_Loss:0.0417 ||Epoch_VAL_Loss:0.0000\n","timer:  434.6579 sec.\n","-------------\n","Epoch 22/30\n","-------------\n","（train）\n","イテレーション 3850 || Loss: 0.0356 || 10iter: 14.6065 sec.\n","イテレーション 3860 || Loss: 0.0395 || 10iter: 21.6921 sec.\n","イテレーション 3870 || Loss: 0.0322 || 10iter: 21.7291 sec.\n","イテレーション 3880 || Loss: 0.0151 || 10iter: 21.7664 sec.\n","イテレーション 3890 || Loss: 0.0435 || 10iter: 21.7095 sec.\n","イテレーション 3900 || Loss: 0.0333 || 10iter: 21.7825 sec.\n","イテレーション 3910 || Loss: 0.0331 || 10iter: 21.6579 sec.\n","イテレーション 3920 || Loss: 0.0390 || 10iter: 21.7068 sec.\n","イテレーション 3930 || Loss: 0.0318 || 10iter: 21.7221 sec.\n","イテレーション 3940 || Loss: 0.0250 || 10iter: 21.7372 sec.\n","イテレーション 3950 || Loss: 0.0696 || 10iter: 21.6874 sec.\n","イテレーション 3960 || Loss: 0.0319 || 10iter: 21.6663 sec.\n","イテレーション 3970 || Loss: 0.0291 || 10iter: 21.7219 sec.\n","イテレーション 3980 || Loss: 0.0490 || 10iter: 21.6914 sec.\n","イテレーション 3990 || Loss: 0.0455 || 10iter: 21.7137 sec.\n","イテレーション 4000 || Loss: 0.0683 || 10iter: 21.7526 sec.\n","イテレーション 4010 || Loss: 0.0457 || 10iter: 21.6926 sec.\n","イテレーション 4020 || Loss: 0.0166 || 10iter: 21.7102 sec.\n","-------------\n","epoch 22 || Epoch_TRAIN_Loss:0.0426 ||Epoch_VAL_Loss:0.0000\n","timer:  435.1678 sec.\n","-------------\n","Epoch 23/30\n","-------------\n","（train）\n","イテレーション 4030 || Loss: 0.0523 || 10iter: 7.4917 sec.\n","イテレーション 4040 || Loss: 0.0408 || 10iter: 21.7462 sec.\n","イテレーション 4050 || Loss: 0.0301 || 10iter: 21.6879 sec.\n","イテレーション 4060 || Loss: 0.0494 || 10iter: 21.7226 sec.\n","イテレーション 4070 || Loss: 0.0387 || 10iter: 21.7219 sec.\n","イテレーション 4080 || Loss: 0.0319 || 10iter: 21.7393 sec.\n","イテレーション 4090 || Loss: 0.0262 || 10iter: 21.7228 sec.\n","イテレーション 4100 || Loss: 0.0296 || 10iter: 21.7240 sec.\n","イテレーション 4110 || Loss: 0.0307 || 10iter: 21.7038 sec.\n","イテレーション 4120 || Loss: 0.0445 || 10iter: 21.7165 sec.\n","イテレーション 4130 || Loss: 0.0529 || 10iter: 21.7703 sec.\n","イテレーション 4140 || Loss: 0.0241 || 10iter: 21.7591 sec.\n","イテレーション 4150 || Loss: 0.0314 || 10iter: 21.6850 sec.\n","イテレーション 4160 || Loss: 0.0529 || 10iter: 21.7529 sec.\n","イテレーション 4170 || Loss: 0.0342 || 10iter: 21.7191 sec.\n","イテレーション 4180 || Loss: 0.0241 || 10iter: 21.7190 sec.\n","イテレーション 4190 || Loss: 0.0392 || 10iter: 21.6574 sec.\n","イテレーション 4200 || Loss: 0.0620 || 10iter: 21.8074 sec.\n","-------------\n","epoch 23 || Epoch_TRAIN_Loss:0.0422 ||Epoch_VAL_Loss:0.0000\n","timer:  435.3421 sec.\n","-------------\n","Epoch 24/30\n","-------------\n","（train）\n","イテレーション 4210 || Loss: 0.0315 || 10iter: 0.3303 sec.\n","イテレーション 4220 || Loss: 0.0347 || 10iter: 21.7449 sec.\n","イテレーション 4230 || Loss: 0.0355 || 10iter: 21.7064 sec.\n","イテレーション 4240 || Loss: 0.0523 || 10iter: 21.7003 sec.\n","イテレーション 4250 || Loss: 0.0326 || 10iter: 21.7373 sec.\n","イテレーション 4260 || Loss: 0.0378 || 10iter: 21.7230 sec.\n","イテレーション 4270 || Loss: 0.0598 || 10iter: 21.7629 sec.\n","イテレーション 4280 || Loss: 0.0753 || 10iter: 21.6600 sec.\n","イテレーション 4290 || Loss: 0.0275 || 10iter: 21.7051 sec.\n","イテレーション 4300 || Loss: 0.0605 || 10iter: 21.7590 sec.\n","イテレーション 4310 || Loss: 0.0316 || 10iter: 21.7647 sec.\n","イテレーション 4320 || Loss: 0.0368 || 10iter: 21.7439 sec.\n","イテレーション 4330 || Loss: 0.0285 || 10iter: 21.7855 sec.\n","イテレーション 4340 || Loss: 0.0326 || 10iter: 21.6641 sec.\n","イテレーション 4350 || Loss: 0.0239 || 10iter: 21.7194 sec.\n","イテレーション 4360 || Loss: 0.0192 || 10iter: 21.6962 sec.\n","イテレーション 4370 || Loss: 0.0550 || 10iter: 21.6604 sec.\n","イテレーション 4380 || Loss: 0.0320 || 10iter: 21.7175 sec.\n","イテレーション 4390 || Loss: 0.0346 || 10iter: 21.7386 sec.\n","-------------\n","epoch 24 || Epoch_TRAIN_Loss:0.0422 ||Epoch_VAL_Loss:0.0000\n","timer:  435.2179 sec.\n","-------------\n","Epoch 25/30\n","-------------\n","（train）\n","イテレーション 4400 || Loss: 0.0454 || 10iter: 16.9735 sec.\n","イテレーション 4410 || Loss: 0.0442 || 10iter: 21.7569 sec.\n","イテレーション 4420 || Loss: 0.0281 || 10iter: 21.8066 sec.\n","イテレーション 4430 || Loss: 0.0159 || 10iter: 21.7922 sec.\n","イテレーション 4440 || Loss: 0.0311 || 10iter: 21.7016 sec.\n","イテレーション 4450 || Loss: 0.0301 || 10iter: 21.7145 sec.\n","イテレーション 4460 || Loss: 0.0549 || 10iter: 21.7654 sec.\n","イテレーション 4470 || Loss: 0.0211 || 10iter: 21.7403 sec.\n","イテレーション 4480 || Loss: 0.0665 || 10iter: 21.7612 sec.\n","イテレーション 4490 || Loss: 0.0145 || 10iter: 21.6603 sec.\n","イテレーション 4500 || Loss: 0.0210 || 10iter: 21.7690 sec.\n","イテレーション 4510 || Loss: 0.0394 || 10iter: 21.7431 sec.\n","イテレーション 4520 || Loss: 0.0529 || 10iter: 21.7306 sec.\n","イテレーション 4530 || Loss: 0.0254 || 10iter: 21.7292 sec.\n","イテレーション 4540 || Loss: 0.0466 || 10iter: 21.8119 sec.\n","イテレーション 4550 || Loss: 0.0553 || 10iter: 21.6925 sec.\n","イテレーション 4560 || Loss: 0.0288 || 10iter: 21.6674 sec.\n","イテレーション 4570 || Loss: 0.0522 || 10iter: 21.6833 sec.\n","-------------\n","（val）\n","-------------\n","epoch 25 || Epoch_TRAIN_Loss:0.0422 ||Epoch_VAL_Loss:0.0704\n","timer:  571.0407 sec.\n","-------------\n","Epoch 26/30\n","-------------\n","（train）\n","イテレーション 4580 || Loss: 0.0411 || 10iter: 9.8255 sec.\n","イテレーション 4590 || Loss: 0.0466 || 10iter: 21.7675 sec.\n","イテレーション 4600 || Loss: 0.0641 || 10iter: 21.7335 sec.\n","イテレーション 4610 || Loss: 0.0439 || 10iter: 21.6908 sec.\n","イテレーション 4620 || Loss: 0.0380 || 10iter: 21.7162 sec.\n","イテレーション 4630 || Loss: 0.0289 || 10iter: 21.7319 sec.\n","イテレーション 4640 || Loss: 0.0328 || 10iter: 21.7027 sec.\n","イテレーション 4650 || Loss: 0.0280 || 10iter: 21.6628 sec.\n","イテレーション 4660 || Loss: 0.0408 || 10iter: 21.7345 sec.\n","イテレーション 4670 || Loss: 0.0466 || 10iter: 21.6850 sec.\n","イテレーション 4680 || Loss: 0.0441 || 10iter: 21.7230 sec.\n","イテレーション 4690 || Loss: 0.0424 || 10iter: 21.7791 sec.\n","イテレーション 4700 || Loss: 0.0335 || 10iter: 21.8369 sec.\n","イテレーション 4710 || Loss: 0.0584 || 10iter: 21.7604 sec.\n","イテレーション 4720 || Loss: 0.0342 || 10iter: 21.7039 sec.\n","イテレーション 4730 || Loss: 0.0305 || 10iter: 21.7715 sec.\n","イテレーション 4740 || Loss: 0.0282 || 10iter: 21.7258 sec.\n","イテレーション 4750 || Loss: 0.0563 || 10iter: 21.7045 sec.\n","-------------\n","epoch 26 || Epoch_TRAIN_Loss:0.0416 ||Epoch_VAL_Loss:0.0000\n","timer:  435.3233 sec.\n","-------------\n","Epoch 27/30\n","-------------\n","（train）\n","イテレーション 4760 || Loss: 0.0431 || 10iter: 2.6978 sec.\n","イテレーション 4770 || Loss: 0.0409 || 10iter: 21.7109 sec.\n","イテレーション 4780 || Loss: 0.0278 || 10iter: 21.7767 sec.\n","イテレーション 4790 || Loss: 0.0415 || 10iter: 21.7279 sec.\n","イテレーション 4800 || Loss: 0.0345 || 10iter: 21.7155 sec.\n","イテレーション 4810 || Loss: 0.0412 || 10iter: 21.7626 sec.\n","イテレーション 4820 || Loss: 0.0386 || 10iter: 21.6608 sec.\n","イテレーション 4830 || Loss: 0.0477 || 10iter: 21.7035 sec.\n","イテレーション 4840 || Loss: 0.0337 || 10iter: 21.7626 sec.\n","イテレーション 4850 || Loss: 0.0474 || 10iter: 21.6811 sec.\n","イテレーション 4860 || Loss: 0.0693 || 10iter: 21.7495 sec.\n","イテレーション 4870 || Loss: 0.0411 || 10iter: 21.7413 sec.\n","イテレーション 4880 || Loss: 0.0505 || 10iter: 21.7311 sec.\n","イテレーション 4890 || Loss: 0.0146 || 10iter: 21.6930 sec.\n","イテレーション 4900 || Loss: 0.0441 || 10iter: 21.6959 sec.\n","イテレーション 4910 || Loss: 0.0382 || 10iter: 21.6636 sec.\n","イテレーション 4920 || Loss: 0.0442 || 10iter: 21.7136 sec.\n","イテレーション 4930 || Loss: 0.0236 || 10iter: 21.6766 sec.\n","イテレーション 4940 || Loss: 0.0267 || 10iter: 21.6930 sec.\n","-------------\n","epoch 27 || Epoch_TRAIN_Loss:0.0395 ||Epoch_VAL_Loss:0.0000\n","timer:  435.0813 sec.\n","-------------\n","Epoch 28/30\n","-------------\n","（train）\n","イテレーション 4950 || Loss: 0.0645 || 10iter: 19.3083 sec.\n","イテレーション 4960 || Loss: 0.0340 || 10iter: 21.6790 sec.\n","イテレーション 4970 || Loss: 0.0611 || 10iter: 21.7122 sec.\n","イテレーション 4980 || Loss: 0.0207 || 10iter: 21.7116 sec.\n","イテレーション 4990 || Loss: 0.0551 || 10iter: 21.7167 sec.\n","イテレーション 5000 || Loss: 0.0631 || 10iter: 21.7075 sec.\n","イテレーション 5010 || Loss: 0.0326 || 10iter: 21.6966 sec.\n","イテレーション 5020 || Loss: 0.0273 || 10iter: 21.7681 sec.\n","イテレーション 5030 || Loss: 0.0471 || 10iter: 21.7056 sec.\n","イテレーション 5040 || Loss: 0.0403 || 10iter: 21.7091 sec.\n","イテレーション 5050 || Loss: 0.0541 || 10iter: 21.7109 sec.\n","イテレーション 5060 || Loss: 0.0316 || 10iter: 21.7301 sec.\n","イテレーション 5070 || Loss: 0.0373 || 10iter: 21.7064 sec.\n","イテレーション 5080 || Loss: 0.0330 || 10iter: 21.7070 sec.\n","イテレーション 5090 || Loss: 0.0479 || 10iter: 21.6924 sec.\n","イテレーション 5100 || Loss: 0.0451 || 10iter: 21.7350 sec.\n","イテレーション 5110 || Loss: 0.0399 || 10iter: 21.7797 sec.\n","イテレーション 5120 || Loss: 0.0473 || 10iter: 21.7554 sec.\n","-------------\n","epoch 28 || Epoch_TRAIN_Loss:0.0408 ||Epoch_VAL_Loss:0.0000\n","timer:  435.1249 sec.\n","-------------\n","Epoch 29/30\n","-------------\n","（train）\n","イテレーション 5130 || Loss: 0.0490 || 10iter: 12.1903 sec.\n","イテレーション 5140 || Loss: 0.0500 || 10iter: 21.7659 sec.\n","イテレーション 5150 || Loss: 0.0298 || 10iter: 21.6880 sec.\n","イテレーション 5160 || Loss: 0.0381 || 10iter: 21.6699 sec.\n","イテレーション 5170 || Loss: 0.0900 || 10iter: 21.6945 sec.\n","イテレーション 5180 || Loss: 0.0476 || 10iter: 21.6822 sec.\n","イテレーション 5190 || Loss: 0.0401 || 10iter: 21.7260 sec.\n","イテレーション 5200 || Loss: 0.0244 || 10iter: 21.6883 sec.\n","イテレーション 5210 || Loss: 0.0315 || 10iter: 21.7119 sec.\n","イテレーション 5220 || Loss: 0.0363 || 10iter: 21.6955 sec.\n","イテレーション 5230 || Loss: 0.0232 || 10iter: 21.7587 sec.\n","イテレーション 5240 || Loss: 0.0405 || 10iter: 21.6678 sec.\n","イテレーション 5250 || Loss: 0.0328 || 10iter: 21.7663 sec.\n","イテレーション 5260 || Loss: 0.0373 || 10iter: 21.7443 sec.\n","イテレーション 5270 || Loss: 0.0431 || 10iter: 21.7113 sec.\n","イテレーション 5280 || Loss: 0.0407 || 10iter: 21.7325 sec.\n","イテレーション 5290 || Loss: 0.0308 || 10iter: 21.6325 sec.\n","イテレーション 5300 || Loss: 0.0659 || 10iter: 21.6468 sec.\n","-------------\n","epoch 29 || Epoch_TRAIN_Loss:0.0396 ||Epoch_VAL_Loss:0.0000\n","timer:  434.8406 sec.\n","-------------\n","Epoch 30/30\n","-------------\n","（train）\n","イテレーション 5310 || Loss: 0.0366 || 10iter: 5.0692 sec.\n","イテレーション 5320 || Loss: 0.0161 || 10iter: 21.7234 sec.\n","イテレーション 5330 || Loss: 0.0316 || 10iter: 21.6428 sec.\n","イテレーション 5340 || Loss: 0.0311 || 10iter: 21.7009 sec.\n","イテレーション 5350 || Loss: 0.0302 || 10iter: 21.7663 sec.\n","イテレーション 5360 || Loss: 0.0520 || 10iter: 21.7293 sec.\n","イテレーション 5370 || Loss: 0.0320 || 10iter: 21.7087 sec.\n","イテレーション 5380 || Loss: 0.0320 || 10iter: 21.7229 sec.\n","イテレーション 5390 || Loss: 0.0318 || 10iter: 21.6650 sec.\n","イテレーション 5400 || Loss: 0.0386 || 10iter: 21.6830 sec.\n","イテレーション 5410 || Loss: 0.0356 || 10iter: 21.7762 sec.\n","イテレーション 5420 || Loss: 0.0249 || 10iter: 21.6692 sec.\n","イテレーション 5430 || Loss: 0.0244 || 10iter: 21.6751 sec.\n","イテレーション 5440 || Loss: 0.0315 || 10iter: 21.8513 sec.\n","イテレーション 5450 || Loss: 0.0289 || 10iter: 21.8302 sec.\n","イテレーション 5460 || Loss: 0.0396 || 10iter: 21.6580 sec.\n","イテレーション 5470 || Loss: 0.0456 || 10iter: 21.7076 sec.\n","イテレーション 5480 || Loss: 0.0383 || 10iter: 21.8197 sec.\n","イテレーション 5490 || Loss: 0.0233 || 10iter: 21.7592 sec.\n","-------------\n","（val）\n","-------------\n","epoch 30 || Epoch_TRAIN_Loss:0.0397 ||Epoch_VAL_Loss:0.0701\n","timer:  571.4796 sec.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zXHjujLZ5Dk8"},"source":["以上"]}]}