{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "7-2_torchtext.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amplil/pytorch/blob/master/7_2_torchtext.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5s-QFKZTWO7C"
      },
      "source": [
        "# 7.2 torchtextでのDataset、DataLoaderの実装方法\n",
        "\n",
        "- 本ファイルでは、torchtextを使用してDatasetおよびDataLoaderを実装する方法を解説します。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGMaoTYIWO7L"
      },
      "source": [
        "※　本章のファイルはすべてUbuntuでの動作を前提としています。Windowsなど文字コードが違う環境での動作にはご注意下さい。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fB79aLQdWO7M"
      },
      "source": [
        "# 7.2 学習目標\n",
        "\n",
        "1.\ttorchtextを用いてDatasetおよびDataLoaderの実装ができる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdL9OhEEWO7M"
      },
      "source": [
        "# 事前準備\n",
        "\n",
        "- 書籍の指示に従い、本章で使用するデータを用意します\n",
        "\n",
        "- torchtextをインストールします\n",
        "\n",
        "- pip install torchtext\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wl-HiklYWO7M"
      },
      "source": [
        "# 1 . 前処理と単語分割の関数を実装\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPYcpGzkWXfy",
        "outputId": "b77339e2-2cca-46ad-b0b9-fb3f54013ee7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_MqDw0uWiW9"
      },
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/Colab Notebooks/packages\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_LJeykWZg_i",
        "outputId": "74e0166c-211e-414b-8f18-470f2be9af7c"
      },
      "source": [
        "cd \"/content/drive/My Drive/Colab Notebooks/pytorch_advanced/7_nlp_sentiment_transformer\""
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/pytorch_advanced/7_nlp_sentiment_transformer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 985
        },
        "id": "f6EyPGASW2GL",
        "outputId": "f9d89169-a799-44d5-aa4c-5ab3ef35a3ef"
      },
      "source": [
        "!pip install --target \"/content/drive/MyDrive/Colab Notebooks/packages\" torchtext"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/50/84184d6230686e230c464f0dd4ff32eada2756b4a0b9cefec68b88d1d580/torchtext-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 5.6MB/s \n",
            "\u001b[?25hCollecting tqdm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/3e/2730d0effc282960dbff3cf91599ad0d8f3faedc8e75720fdf224b31ab24/tqdm-4.59.0-py2.py3-none-any.whl (74kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.6MB/s \n",
            "\u001b[?25hCollecting torch==1.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/99/5861239a6e1ffe66e120f114a4d67e96e5c4b17c1a785dfc6ca6769585fc/torch-1.8.0-cp37-cp37m-manylinux1_x86_64.whl (735.5MB)\n",
            "\u001b[K     |████████████████████████████████| 735.5MB 25kB/s \n",
            "\u001b[?25hCollecting numpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/8a/064b4077e3d793f877e3b77aa64f56fa49a4d37236a53f78ee28be009a16/numpy-1.20.1-cp37-cp37m-manylinux2010_x86_64.whl (15.3MB)\n",
            "\u001b[K     |████████████████████████████████| 15.3MB 262kB/s \n",
            "\u001b[?25hCollecting requests\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/c1/24814557f1d22c56d50280771a17307e6bf87b70727d975fd6b2ce6b014a/requests-2.25.1-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.9MB/s \n",
            "\u001b[?25hCollecting typing-extensions\n",
            "  Downloading https://files.pythonhosted.org/packages/60/7a/e881b5abb54db0e6e671ab088d079c57ce54e8a01a3ca443f561ccadb37e/typing_extensions-3.7.4.3-py3-none-any.whl\n",
            "Collecting certifi>=2017.4.17\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/a0/5f06e1e1d463903cf0c0eebeb751791119ed7a4b3737fdc9a77f1cdfb51f/certifi-2020.12.5-py2.py3-none-any.whl (147kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 55.0MB/s \n",
            "\u001b[?25hCollecting idna<3,>=2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/38/928ddce2273eaa564f6f50de919327bf3a00f091b5baba8dfa9460f3a8a8/idna-2.10-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.9MB/s \n",
            "\u001b[?25hCollecting chardet<5,>=3.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/c7/fa589626997dd07bd87d9269342ccb74b1720384a4d739a1872bd84fbe68/chardet-4.0.0-py2.py3-none-any.whl (178kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 64.0MB/s \n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/c6/d3e3abe5b4f4f16cf0dfc9240ab7ce10c2baa0e268989a4e3ec19e90c84e/urllib3-1.26.4-py2.py3-none-any.whl (153kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 55.1MB/s \n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement numpy~=1.19.2, but you'll have numpy 1.20.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tqdm, typing-extensions, numpy, torch, certifi, idna, chardet, urllib3, requests, torchtext\n",
            "Successfully installed certifi-2020.12.5 chardet-4.0.0 idna-2.10 numpy-1.20.1 requests-2.25.1 torch-1.8.0 torchtext-0.9.0 tqdm-4.59.0 typing-extensions-3.7.4.3 urllib3-1.26.4\n",
            "\u001b[33mWARNING: Target directory /content/drive/MyDrive/Colab Notebooks/packages/chardet already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/drive/MyDrive/Colab Notebooks/packages/certifi already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/drive/MyDrive/Colab Notebooks/packages/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/drive/MyDrive/Colab Notebooks/packages/tqdm already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/drive/MyDrive/Colab Notebooks/packages/typing_extensions.py already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/drive/MyDrive/Colab Notebooks/packages/typing_extensions-3.7.4.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/drive/MyDrive/Colab Notebooks/packages/numpy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/drive/MyDrive/Colab Notebooks/packages/caffe2 already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/drive/MyDrive/Colab Notebooks/packages/urllib3 already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/drive/MyDrive/Colab Notebooks/packages/numpy already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/drive/MyDrive/Colab Notebooks/packages/idna-2.10.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/drive/MyDrive/Colab Notebooks/packages/idna already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/drive/MyDrive/Colab Notebooks/packages/requests already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/drive/MyDrive/Colab Notebooks/packages/bin already exists. Specify --upgrade to force replacement.\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "idna",
                  "torchtext",
                  "typing_extensions"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV6xHnE3WO7N"
      },
      "source": [
        "# 単語分割にはJanomeを使用\n",
        "from janome.tokenizer import Tokenizer\n",
        "\n",
        "j_t = Tokenizer()\n",
        "\n",
        "\n",
        "def tokenizer_janome(text):\n",
        "    return [tok for tok in j_t.tokenize(text, wakati=True)]\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pr7pJZaKWO7N"
      },
      "source": [
        "# 前処理として正規化をする関数を定義\n",
        "import re\n",
        "\n",
        "\n",
        "def preprocessing_text(text):\n",
        "    # 半角・全角の統一\n",
        "    # 今回は無視\n",
        "\n",
        "    # 英語の小文字化\n",
        "    # 今回はここでは無視\n",
        "    # output = output.lower()\n",
        "\n",
        "    # 改行、半角スペース、全角スペースを削除\n",
        "    text = re.sub('\\r', '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub('　', '', text)\n",
        "    text = re.sub(' ', '', text)\n",
        "\n",
        "    # 数字文字の一律「0」化\n",
        "    text = re.sub(r'[0-9 ０-９]', '0', text)  # 数字\n",
        "\n",
        "    # 記号と数字の除去\n",
        "    # 今回は無視。半角記号,数字,英字\n",
        "    # 今回は無視。全角記号\n",
        "\n",
        "    # 特定文字を正規表現で置換する\n",
        "    # 今回は無視\n",
        "\n",
        "    return text\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2TkJOOtWO7O",
        "outputId": "ab422ed4-e18c-4aad-c5b1-752742b02613"
      },
      "source": [
        "# 前処理とJanomeの単語分割を合わせた関数を定義する\n",
        "\n",
        "\n",
        "def tokenizer_with_preprocessing(text):\n",
        "    text = preprocessing_text(text)  # 前処理の正規化\n",
        "    ret = tokenizer_janome(text)  # Janomeの単語分割\n",
        "\n",
        "    return ret\n",
        "\n",
        "\n",
        "# 動作確認\n",
        "text = \"昨日は とても暑く、気温が36度もあった。\"\n",
        "print(tokenizer_with_preprocessing(text))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['昨日', 'は', 'とても', '暑く', '、', '気温', 'が', '00', '度', 'も', 'あっ', 'た', '。']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YzS2miLWO7P"
      },
      "source": [
        "# 2. 文章データの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ogk7QtDkWO7Q"
      },
      "source": [
        "import torchtext\n",
        "\n",
        "# tsvやcsvデータを読み込んだときに、読み込んだ内容に対して行う処理を定義します\n",
        "# 文章とラベルの両方に用意します\n",
        "\n",
        "max_length = 25\n",
        "TEXT = torchtext.legacy.data.Field(sequential=True, tokenize=tokenizer_with_preprocessing,\n",
        "                            use_vocab=True, lower=True, include_lengths=True, batch_first=True, fix_length=max_length)\n",
        "LABEL = torchtext.legacy.data.Field(sequential=False, use_vocab=False)\n",
        "\n",
        "# 引数の意味は次の通り\n",
        "# sequential: データの長さが可変か？文章は長さがいろいろなのでTrue.ラベルはFalse\n",
        "# tokenize: 文章を読み込んだときに、前処理や単語分割をするための関数を定義\n",
        "# use_vocab：単語をボキャブラリー（単語集：後で解説）に追加するかどうか\n",
        "# lower：アルファベットがあったときに小文字に変換するかどうか\n",
        "# include_length: 文章の単語数のデータを保持するか\n",
        "# batch_first：ミニバッチの次元を先頭に用意するかどうか\n",
        "# fix_length：全部の文章を指定した長さと同じになるように、paddingします\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbR5T9M5WO7Q",
        "outputId": "0a7cd87e-0aee-40ef-e6d4-0650ca09418d"
      },
      "source": [
        "# data.TabularDataset 詳細\n",
        "# https://torchtext.readthedocs.io/en/latest/examples.html?highlight=data.TabularDataset.splits\n",
        "\n",
        "# フォルダ「data」から各tsvファイルを読み込み、Datasetにします\n",
        "# 1行がTEXTとLABELで区切られていることをfieldsで指示します\n",
        "train_ds, val_ds, test_ds = torchtext.legacy.data.TabularDataset.splits(\n",
        "    path='./data/', train='text_train.tsv',\n",
        "    validation='text_val.tsv', test='text_test.tsv', format='tsv',\n",
        "    fields=[('Text', TEXT), ('Label', LABEL)])\n",
        "\n",
        "\n",
        "# 動作確認\n",
        "print('訓練データの数', len(train_ds))\n",
        "print('1つ目の訓練データ', vars(train_ds[0]))\n",
        "print('2つ目の訓練データ', vars(train_ds[1]))\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "訓練データの数 4\n",
            "1つ目の訓練データ {'Text': ['王', 'と', '王子', 'と', '女王', 'と', '姫', 'と', '男性', 'と', '女性', 'が', 'い', 'まし', 'た', '。'], 'Label': '0'}\n",
            "2つ目の訓練データ {'Text': ['機械', '学習', 'が', '好き', 'です', '。'], 'Label': '1'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_eQWK7lWO7Q"
      },
      "source": [
        "# 単語の数値化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtRz_T6HWO7R",
        "outputId": "d1debfd4-8318-42ae-b2b4-cc4ecaf30d9e"
      },
      "source": [
        "# ボキャブラリーを作成します\n",
        "# 訓練データtrainの単語からmin_freq以上の頻度の単語を使用してボキャブラリー（単語集）を構築\n",
        "TEXT.build_vocab(train_ds, min_freq=1)\n",
        "\n",
        "# 訓練データ内の単語と頻度を出力(頻度min_freqより大きいものが出力されます)\n",
        "TEXT.vocab.freqs  # 出力させる\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'0': 1,\n",
              "         '、': 3,\n",
              "         '。': 4,\n",
              "         'い': 1,\n",
              "         'いる': 2,\n",
              "         'か': 2,\n",
              "         'から': 1,\n",
              "         'が': 3,\n",
              "         'し': 3,\n",
              "         'する': 1,\n",
              "         'その': 1,\n",
              "         'た': 1,\n",
              "         'て': 2,\n",
              "         'で': 1,\n",
              "         'です': 1,\n",
              "         'と': 5,\n",
              "         'な': 4,\n",
              "         'に': 1,\n",
              "         'に対して': 1,\n",
              "         'の': 4,\n",
              "         'は': 1,\n",
              "         'まし': 1,\n",
              "         'ます': 2,\n",
              "         'を': 3,\n",
              "         'クラス': 1,\n",
              "         'ネガティブ': 1,\n",
              "         'ポジティブ': 1,\n",
              "         'モデル': 1,\n",
              "         'レビュー': 1,\n",
              "         '値': 1,\n",
              "         '処理': 1,\n",
              "         '分類': 2,\n",
              "         '取り組み': 1,\n",
              "         '商品': 1,\n",
              "         '女性': 1,\n",
              "         '女王': 1,\n",
              "         '好き': 1,\n",
              "         '姫': 1,\n",
              "         '学習': 1,\n",
              "         '文章': 4,\n",
              "         '本章': 2,\n",
              "         '構築': 1,\n",
              "         '機械': 1,\n",
              "         '王': 1,\n",
              "         '王子': 1,\n",
              "         '男性': 1,\n",
              "         '短い': 1,\n",
              "         '自然': 1,\n",
              "         '言語': 1,\n",
              "         '評価': 2})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoE51dPWWO7R",
        "outputId": "fa000ba4-1a6d-4323-de8a-43d7f1185051"
      },
      "source": [
        "# ボキャブラリーの単語をidに変換した結果を出力。\n",
        "# 頻度がmin_freqより小さい場合は未知語<unk>になる\n",
        "\n",
        "TEXT.vocab.stoi  # 出力。string to identifiers 文字列をidへ\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x7fcdb7c94790>>,\n",
              "            {'0': 18,\n",
              "             '<pad>': 1,\n",
              "             '<unk>': 0,\n",
              "             '、': 7,\n",
              "             '。': 3,\n",
              "             'い': 19,\n",
              "             'いる': 11,\n",
              "             'か': 12,\n",
              "             'から': 20,\n",
              "             'が': 8,\n",
              "             'し': 9,\n",
              "             'する': 21,\n",
              "             'その': 22,\n",
              "             'た': 23,\n",
              "             'て': 13,\n",
              "             'で': 24,\n",
              "             'です': 25,\n",
              "             'と': 2,\n",
              "             'な': 4,\n",
              "             'に': 26,\n",
              "             'に対して': 27,\n",
              "             'の': 5,\n",
              "             'は': 28,\n",
              "             'まし': 29,\n",
              "             'ます': 14,\n",
              "             'を': 10,\n",
              "             'クラス': 30,\n",
              "             'ネガティブ': 31,\n",
              "             'ポジティブ': 32,\n",
              "             'モデル': 33,\n",
              "             'レビュー': 34,\n",
              "             '値': 35,\n",
              "             '処理': 36,\n",
              "             '分類': 15,\n",
              "             '取り組み': 37,\n",
              "             '商品': 38,\n",
              "             '女性': 39,\n",
              "             '女王': 40,\n",
              "             '好き': 41,\n",
              "             '姫': 42,\n",
              "             '学習': 43,\n",
              "             '文章': 6,\n",
              "             '本章': 16,\n",
              "             '構築': 44,\n",
              "             '機械': 45,\n",
              "             '王': 46,\n",
              "             '王子': 47,\n",
              "             '男性': 48,\n",
              "             '短い': 49,\n",
              "             '自然': 50,\n",
              "             '言語': 51,\n",
              "             '評価': 17})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzCOfUTXWO7R"
      },
      "source": [
        "# DataLoaderの作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGoONEugWO7S",
        "outputId": "2bc90d23-5837-478e-9ce2-e8f412aeaeb3"
      },
      "source": [
        "# DataLoaderを作成します（torchtextの文脈では単純にiteraterと呼ばれています）\n",
        "train_dl = torchtext.legacy.data.Iterator(train_ds, batch_size=2, train=True)\n",
        "\n",
        "val_dl = torchtext.legacy.data.Iterator(\n",
        "    val_ds, batch_size=2, train=False, sort=False)\n",
        "\n",
        "test_dl = torchtext.legacy.data.Iterator(\n",
        "    test_ds, batch_size=2, train=False, sort=False)\n",
        "\n",
        "\n",
        "# 動作確認 検証データのデータセットで確認\n",
        "batch = next(iter(val_dl))\n",
        "print(batch.Text)\n",
        "print(batch.Label)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[46,  2, 47,  2, 40,  2, 42,  2, 48,  2, 39,  8, 19, 29, 23,  3,  1,  1,\n",
            "          1,  1,  1,  1,  1,  1,  1],\n",
            "        [45, 43,  8, 41, 25,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "          1,  1,  1,  1,  1,  1,  1]]), tensor([16,  6]))\n",
            "tensor([0, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zol3hIfOWO7S"
      },
      "source": [
        "以上"
      ]
    }
  ]
}