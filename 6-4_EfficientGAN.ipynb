{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"colab":{"name":"6-4_EfficientGAN.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"7ZaLsEIeL8J7"},"source":["# 6.4 Efficient GANの作成\n","\n","- 本ファイルでは、Efficient GANのネットワークを実装し、学習をします。\n"]},{"cell_type":"markdown","metadata":{"id":"ey6RtLORL8KI"},"source":["# 6.4 学習目標\n","\n","1.\tEfficient GANを実装し、手書き数字画像で異常検知が生成できる"]},{"cell_type":"markdown","metadata":{"id":"LNnV0rM1L8KK"},"source":["# 事前準備\n","書籍の指示に従い、本章で使用するデータを用意します"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xy-w6Idor_QN","executionInfo":{"status":"ok","timestamp":1615355499610,"user_tz":-540,"elapsed":28524,"user":{"displayName":"Operational Amplifier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3etudnjCRnCXOZeYBsRUFbwA5_hCPRQvY_sSe=s64","userId":"13448740953613370666"}},"outputId":"afd25bfc-fca1-4da9-c138-cc7433a61222"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f4Gp5Xz1sAP2","executionInfo":{"status":"ok","timestamp":1615355499873,"user_tz":-540,"elapsed":1829,"user":{"displayName":"Operational Amplifier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3etudnjCRnCXOZeYBsRUFbwA5_hCPRQvY_sSe=s64","userId":"13448740953613370666"}},"outputId":"69cd8ba2-9c5f-44c2-cfce-81e69bd831d1"},"source":["cd \"/content/drive/My Drive/Colab Notebooks/pytorch_advanced/6_gan_anomaly_detection\""],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/pytorch_advanced/6_gan_anomaly_detection\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_lGX1rk4L8KL","executionInfo":{"status":"ok","timestamp":1615355537484,"user_tz":-540,"elapsed":3807,"user":{"displayName":"Operational Amplifier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3etudnjCRnCXOZeYBsRUFbwA5_hCPRQvY_sSe=s64","userId":"13448740953613370666"}}},"source":["# パッケージのimport\n","import random\n","import math\n","import time\n","import pandas as pd\n","import numpy as np\n","from PIL import Image\n","\n","import torch\n","import torch.utils.data as data\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from torchvision import transforms"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"EKc25TAjL8KP","executionInfo":{"status":"ok","timestamp":1615355537494,"user_tz":-540,"elapsed":3811,"user":{"displayName":"Operational Amplifier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3etudnjCRnCXOZeYBsRUFbwA5_hCPRQvY_sSe=s64","userId":"13448740953613370666"}}},"source":["# Setup seeds\n","torch.manual_seed(1234)\n","torch.cuda.manual_seed(1234)\n","np.random.seed(1234)\n","random.seed(1234)\n"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vlfVYAe2L8KR"},"source":["# Generatorの実装\n","\n"]},{"cell_type":"code","metadata":{"id":"68sd3hevL8KS","executionInfo":{"status":"ok","timestamp":1615355537497,"user_tz":-540,"elapsed":3810,"user":{"displayName":"Operational Amplifier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3etudnjCRnCXOZeYBsRUFbwA5_hCPRQvY_sSe=s64","userId":"13448740953613370666"}}},"source":["class Generator(nn.Module):\n","\n","    def __init__(self, z_dim=20):\n","        super(Generator, self).__init__()\n","\n","        self.layer1 = nn.Sequential(\n","            nn.Linear(z_dim, 1024),\n","            nn.BatchNorm1d(1024),\n","            nn.ReLU(inplace=True))\n","\n","        self.layer2 = nn.Sequential(\n","            nn.Linear(1024, 7*7*128),\n","            nn.BatchNorm1d(7*7*128),\n","            nn.ReLU(inplace=True))\n","\n","        self.layer3 = nn.Sequential(\n","            nn.ConvTranspose2d(in_channels=128, out_channels=64,\n","                               kernel_size=4, stride=2, padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(inplace=True))\n","\n","        self.last = nn.Sequential(\n","            nn.ConvTranspose2d(in_channels=64, out_channels=1,\n","                               kernel_size=4, stride=2, padding=1),\n","            nn.Tanh())\n","        # 注意：白黒画像なので出力チャネルは1つだけ\n","\n","    def forward(self, z):\n","        out = self.layer1(z)\n","        out = self.layer2(out)\n","\n","        # 転置畳み込み層に入れるためにテンソルの形を整形\n","        out = out.view(z.shape[0], 128, 7, 7)\n","        out = self.layer3(out)\n","        out = self.last(out)\n","\n","        return out\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"zWygUNjSL8KU","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1615355538377,"user_tz":-540,"elapsed":4686,"user":{"displayName":"Operational Amplifier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3etudnjCRnCXOZeYBsRUFbwA5_hCPRQvY_sSe=s64","userId":"13448740953613370666"}},"outputId":"0af6933f-8eb5-4945-cbca-eb0a5c9e1733"},"source":["# 動作確認\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","G = Generator(z_dim=20)\n","G.train()\n","\n","# 入力する乱数\n","# バッチノーマライゼーションがあるのでミニバッチ数は2以上\n","input_z = torch.randn(2, 20)\n","\n","# 偽画像を出力\n","fake_images = G(input_z)  # torch.Size([2, 1, 28, 28])\n","img_transformed = fake_images[0][0].detach().numpy()\n","plt.imshow(img_transformed, 'gray')\n","plt.show()\n"],"execution_count":6,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"YIyWxLJPL8KW"},"source":["# Discriminatorの実装"]},{"cell_type":"code","metadata":{"id":"ug0Iof6uL8KX","executionInfo":{"status":"ok","timestamp":1615355538380,"user_tz":-540,"elapsed":4686,"user":{"displayName":"Operational Amplifier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3etudnjCRnCXOZeYBsRUFbwA5_hCPRQvY_sSe=s64","userId":"13448740953613370666"}}},"source":["class Discriminator(nn.Module):\n","\n","    def __init__(self, z_dim=20):\n","        super(Discriminator, self).__init__()\n","\n","        # 画像側の入力処理\n","        self.x_layer1 = nn.Sequential(\n","            nn.Conv2d(1, 64, kernel_size=4,\n","                      stride=2, padding=1),\n","            nn.LeakyReLU(0.1, inplace=True))\n","        # 注意：白黒画像なので入力チャネルは1つだけ\n","\n","        self.x_layer2 = nn.Sequential(\n","            nn.Conv2d(64, 64, kernel_size=4,\n","                      stride=2, padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.LeakyReLU(0.1, inplace=True))\n","\n","        # 乱数側の入力処理\n","        self.z_layer1 = nn.Linear(z_dim, 512)\n","\n","        # 最後の判定\n","        self.last1 = nn.Sequential(\n","            nn.Linear(3648, 1024),\n","            nn.LeakyReLU(0.1, inplace=True))\n","\n","        self.last2 = nn.Linear(1024, 1)\n","\n","    def forward(self, x, z):\n","\n","        # 画像側の入力処理\n","        x_out = self.x_layer1(x)\n","        x_out = self.x_layer2(x_out)\n","\n","        # 乱数側の入力処理\n","        z = z.view(z.shape[0], -1)\n","        z_out = self.z_layer1(z)\n","\n","        # x_outとz_outを結合し、全結合層で判定\n","        x_out = x_out.view(-1, 64 * 7 * 7)\n","        out = torch.cat([x_out, z_out], dim=1)\n","        out = self.last1(out)\n","\n","        feature = out  # 最後にチャネルを1つに集約する手前の情報\n","        feature = feature.view(feature.size()[0], -1)  # 2次元に変換\n","\n","        out = self.last2(out)\n","\n","        return out, feature\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"fsKNLk4BL8Ka","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615355538382,"user_tz":-540,"elapsed":4686,"user":{"displayName":"Operational Amplifier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3etudnjCRnCXOZeYBsRUFbwA5_hCPRQvY_sSe=s64","userId":"13448740953613370666"}},"outputId":"64ae5e05-b988-41d5-b827-09c4299cbe0d"},"source":["# 動作確認\n","D = Discriminator(z_dim=20)\n","\n","# 偽画像を生成\n","input_z = torch.randn(2, 20)\n","fake_images = G(input_z)\n","\n","# 偽画像をDに入力\n","d_out, _ = D(fake_images, input_z)\n","\n","# 出力d_outにSigmoidをかけて0から1に変換\n","print(nn.Sigmoid()(d_out))\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["tensor([[0.4322],\n","        [0.4629]], grad_fn=<SigmoidBackward>)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YlRmvebQL8Kd"},"source":["# Encoderの実装\n","\n","画像をzに変換する"]},{"cell_type":"code","metadata":{"id":"Ih6gWabsL8Kd","executionInfo":{"status":"ok","timestamp":1615355538384,"user_tz":-540,"elapsed":4685,"user":{"displayName":"Operational Amplifier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3etudnjCRnCXOZeYBsRUFbwA5_hCPRQvY_sSe=s64","userId":"13448740953613370666"}}},"source":["class Encoder(nn.Module):\n","\n","    def __init__(self, z_dim=20):\n","        super(Encoder, self).__init__()\n","\n","        self.layer1 = nn.Sequential(\n","            nn.Conv2d(1, 32, kernel_size=3,\n","                      stride=1),\n","            nn.LeakyReLU(0.1, inplace=True))\n","        # 注意：白黒画像なので入力チャネルは1つだけ\n","\n","        self.layer2 = nn.Sequential(\n","            nn.Conv2d(32, 64, kernel_size=3,\n","                      stride=2, padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.LeakyReLU(0.1, inplace=True))\n","\n","        self.layer3 = nn.Sequential(\n","            nn.Conv2d(64, 128, kernel_size=3,\n","                      stride=2, padding=1),\n","            nn.BatchNorm2d(128),\n","            nn.LeakyReLU(0.1, inplace=True))\n","\n","        # ここまでで画像のサイズは7×7になっている\n","        self.last = nn.Linear(128 * 7 * 7, z_dim)\n","\n","    def forward(self, x):\n","        out = self.layer1(x)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","\n","        # FCに入れるためにテンソルの形を整形\n","        out = out.view(-1, 128 * 7 * 7)\n","        out = self.last(out)\n","\n","        return out\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vun_KvShL8Kh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615355538386,"user_tz":-540,"elapsed":4683,"user":{"displayName":"Operational Amplifier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3etudnjCRnCXOZeYBsRUFbwA5_hCPRQvY_sSe=s64","userId":"13448740953613370666"}},"outputId":"6001a4fa-8a73-4941-da05-e3c8a75d3fc9"},"source":["# 動作確認\n","E = Encoder(z_dim=20)\n","\n","# 入力する画像データ\n","x = fake_images  # fake_imagesは上のGで作成したもの\n","\n","# 画像からzをEncode\n","z = E(x)\n","\n","print(z.shape)\n","print(z)\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["torch.Size([2, 20])\n","tensor([[-0.0669, -0.2844, -0.3601,  0.1404, -0.2922, -0.4834, -0.0025,  0.0258,\n","         -0.1298, -0.2613, -0.4292, -0.2584, -0.6141, -0.1440,  0.1142,  0.2175,\n","          0.0730,  0.0323, -0.7176, -0.7410],\n","        [ 0.4822,  0.3681, -0.0647, -0.0773,  0.0989,  0.3012,  0.8054,  0.4399,\n","          1.0848, -0.2809,  0.0619, -0.3179, -0.2963, -0.1192,  0.6562, -0.1707,\n","          0.1287, -0.6156,  0.3127, -0.4819]], grad_fn=<AddmmBackward>)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BnwXk0a-L8Kl"},"source":["# DataLoaderの作成"]},{"cell_type":"code","metadata":{"id":"8lXhlnQKL8Kl","executionInfo":{"status":"ok","timestamp":1615355731127,"user_tz":-540,"elapsed":521,"user":{"displayName":"Operational Amplifier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3etudnjCRnCXOZeYBsRUFbwA5_hCPRQvY_sSe=s64","userId":"13448740953613370666"}}},"source":["def make_datapath_list():\n","    \"\"\"学習、検証の画像データとアノテーションデータへのファイルパスリストを作成する。 \"\"\"\n","\n","    train_img_list = list()  # 画像ファイルパスを格納\n","\n","    for img_idx in range(200):\n","        img_path = \"./../data/img_78_28size/img_7_\" + str(img_idx)+'.jpg'\n","        train_img_list.append(img_path)\n","\n","        img_path = \"./../data/img_78_28size/img_8_\" + str(img_idx)+'.jpg'\n","        train_img_list.append(img_path)\n","\n","    return train_img_list\n"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"ffLPO9nJL8Kn","executionInfo":{"status":"ok","timestamp":1615355731726,"user_tz":-540,"elapsed":1108,"user":{"displayName":"Operational Amplifier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3etudnjCRnCXOZeYBsRUFbwA5_hCPRQvY_sSe=s64","userId":"13448740953613370666"}}},"source":["class ImageTransform():\n","    \"\"\"画像の前処理クラス\"\"\"\n","\n","    def __init__(self, mean, std):\n","        self.data_transform = transforms.Compose([\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean, std)\n","        ])\n","\n","    def __call__(self, img):\n","        return self.data_transform(img)\n"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pc4oS_UML8Kq","executionInfo":{"status":"ok","timestamp":1615355731729,"user_tz":-540,"elapsed":1107,"user":{"displayName":"Operational Amplifier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3etudnjCRnCXOZeYBsRUFbwA5_hCPRQvY_sSe=s64","userId":"13448740953613370666"}}},"source":["class GAN_Img_Dataset(data.Dataset):\n","    \"\"\"画像のDatasetクラス。PyTorchのDatasetクラスを継承\"\"\"\n","\n","    def __init__(self, file_list, transform):\n","        self.file_list = file_list\n","        self.transform = transform\n","\n","    def __len__(self):\n","        '''画像の枚数を返す'''\n","        return len(self.file_list)\n","\n","    def __getitem__(self, index):\n","        '''前処理をした画像のTensor形式のデータを取得'''\n","\n","        img_path = self.file_list[index]\n","        img = Image.open(img_path)  # [高さ][幅]白黒\n","\n","        # 画像の前処理\n","        img_transformed = self.transform(img)\n","\n","        return img_transformed\n"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"IfBEgPZUL8Ks","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615355751231,"user_tz":-540,"elapsed":20595,"user":{"displayName":"Operational Amplifier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3etudnjCRnCXOZeYBsRUFbwA5_hCPRQvY_sSe=s64","userId":"13448740953613370666"}},"outputId":"53ccd4b4-e71a-42ba-d849-704e3c23a6c3"},"source":["# DataLoaderの作成と動作確認\n","\n","# ファイルリストを作成\n","train_img_list=make_datapath_list()\n","\n","# Datasetを作成\n","mean = (0.5,)\n","std = (0.5,)\n","train_dataset = GAN_Img_Dataset(\n","    file_list=train_img_list, transform=ImageTransform(mean, std))\n","\n","# DataLoaderを作成\n","batch_size = 64\n","\n","train_dataloader = torch.utils.data.DataLoader(\n","    train_dataset, batch_size=batch_size, shuffle=True)\n","\n","# 動作の確認\n","batch_iterator = iter(train_dataloader)  # イテレータに変換\n","imges = next(batch_iterator)  # 1番目の要素を取り出す\n","print(imges.size())  # torch.Size([64, 1, 64, 64])\n"],"execution_count":19,"outputs":[{"output_type":"stream","text":["torch.Size([64, 1, 28, 28])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"j9vLW5T6L8Ku"},"source":["# 学習させる"]},{"cell_type":"code","metadata":{"id":"SDF9_QozL8Kv","executionInfo":{"status":"ok","timestamp":1615355751233,"user_tz":-540,"elapsed":20590,"user":{"displayName":"Operational Amplifier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3etudnjCRnCXOZeYBsRUFbwA5_hCPRQvY_sSe=s64","userId":"13448740953613370666"}}},"source":["# モデルを学習させる関数を作成\n","\n","\n","def train_model(G, D, E, dataloader, num_epochs):\n","\n","    # GPUが使えるかを確認\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    print(\"使用デバイス：\", device)\n","\n","    # 最適化手法の設定\n","    lr_ge = 0.0001\n","    lr_d = 0.0001/4\n","    beta1, beta2 = 0.5, 0.999\n","    g_optimizer = torch.optim.Adam(G.parameters(), lr_ge, [beta1, beta2])\n","    e_optimizer = torch.optim.Adam(E.parameters(), lr_ge, [beta1, beta2])\n","    d_optimizer = torch.optim.Adam(D.parameters(), lr_d, [beta1, beta2])\n","\n","    # 誤差関数を定義\n","    # BCEWithLogitsLossは入力にシグモイド（logit）をかけてから、\n","    # バイナリークロスエントロピーを計算\n","    criterion = nn.BCEWithLogitsLoss(reduction='mean')\n","\n","    # パラメータをハードコーディング\n","    z_dim = 20\n","    mini_batch_size = 64\n","\n","    # ネットワークをGPUへ\n","    G.to(device)\n","    E.to(device)\n","    D.to(device)\n","\n","    G.train()  # モデルを訓練モードに\n","    E.train()  # モデルを訓練モードに\n","    D.train()  # モデルを訓練モードに\n","\n","    # ネットワークがある程度固定であれば、高速化させる\n","    torch.backends.cudnn.benchmark = True\n","\n","    # 画像の枚数\n","    num_train_imgs = len(dataloader.dataset)\n","    batch_size = dataloader.batch_size\n","\n","    # イテレーションカウンタをセット\n","    iteration = 1\n","    logs = []\n","\n","    # epochのループ\n","    for epoch in range(num_epochs):\n","\n","        # 開始時刻を保存\n","        t_epoch_start = time.time()\n","        epoch_g_loss = 0.0  # epochの損失和\n","        epoch_e_loss = 0.0  # epochの損失和\n","        epoch_d_loss = 0.0  # epochの損失和\n","\n","        print('-------------')\n","        print('Epoch {}/{}'.format(epoch, num_epochs))\n","        print('-------------')\n","        print('（train）')\n","\n","        # データローダーからminibatchずつ取り出すループ\n","        for imges in dataloader:\n","\n","            # ミニバッチがサイズが1だと、バッチノーマライゼーションでエラーになるのでさける\n","            if imges.size()[0] == 1:\n","                continue\n","\n","            # ミニバッチサイズの1もしくは0のラベル役のテンソルを作成\n","            # 正解ラベルと偽ラベルを作成\n","            # epochの最後のイテレーションはミニバッチの数が少なくなる\n","            mini_batch_size = imges.size()[0]\n","            label_real = torch.full((mini_batch_size,), 1).to(device)\n","            label_fake = torch.full((mini_batch_size,), 0).to(device)\n","\n","            # GPUが使えるならGPUにデータを送る\n","            imges = imges.to(device)\n","\n","            # --------------------\n","            # 1. Discriminatorの学習\n","            # --------------------\n","            # 真の画像を判定　\n","            z_out_real = E(imges)\n","            d_out_real, _ = D(imges, z_out_real)\n","\n","            # 偽の画像を生成して判定\n","            input_z = torch.randn(mini_batch_size, z_dim).to(device)\n","            fake_images = G(input_z)\n","            d_out_fake, _ = D(fake_images, input_z)\n","\n","            # 誤差を計算\n","            d_loss_real = criterion(d_out_real.view(-1), label_real)\n","            d_loss_fake = criterion(d_out_fake.view(-1), label_fake)\n","            d_loss = d_loss_real + d_loss_fake\n","\n","            # バックプロパゲーション\n","            d_optimizer.zero_grad()\n","            d_loss.backward()\n","            d_optimizer.step()\n","\n","            # --------------------\n","            # 2. Generatorの学習\n","            # --------------------\n","            # 偽の画像を生成して判定\n","            input_z = torch.randn(mini_batch_size, z_dim).to(device)\n","            fake_images = G(input_z)\n","            d_out_fake, _ = D(fake_images, input_z)\n","\n","            # 誤差を計算\n","            g_loss = criterion(d_out_fake.view(-1), label_real)\n","\n","            # バックプロパゲーション\n","            g_optimizer.zero_grad()\n","            g_loss.backward()\n","            g_optimizer.step()\n","\n","            # --------------------\n","            # 3. Encoderの学習\n","            # --------------------\n","            # 真の画像のzを推定\n","            z_out_real = E(imges)\n","            d_out_real, _ = D(imges, z_out_real)\n","\n","            # 誤差を計算\n","            e_loss = criterion(d_out_real.view(-1), label_fake)\n","\n","            # バックプロパゲーション\n","            e_optimizer.zero_grad()\n","            e_loss.backward()\n","            e_optimizer.step()\n","\n","            # --------------------\n","            # 4. 記録\n","            # --------------------\n","            epoch_d_loss += d_loss.item()\n","            epoch_g_loss += g_loss.item()\n","            epoch_e_loss += e_loss.item()\n","            iteration += 1\n","\n","        # epochのphaseごとのlossと正解率\n","        t_epoch_finish = time.time()\n","        print('-------------')\n","        print('epoch {} || Epoch_D_Loss:{:.4f} ||Epoch_G_Loss:{:.4f} ||Epoch_E_Loss:{:.4f}'.format(\n","            epoch, epoch_d_loss/batch_size, epoch_g_loss/batch_size, epoch_e_loss/batch_size))\n","        print('timer:  {:.4f} sec.'.format(t_epoch_finish - t_epoch_start))\n","        t_epoch_start = time.time()\n","\n","    print(\"総イテレーション回数:\", iteration)\n","\n","    return G, D, E\n"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"3o7-C9d7L8Kz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615355751431,"user_tz":-540,"elapsed":20784,"user":{"displayName":"Operational Amplifier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3etudnjCRnCXOZeYBsRUFbwA5_hCPRQvY_sSe=s64","userId":"13448740953613370666"}},"outputId":"1ccab5b0-a5f1-48eb-cd37-0ed5d0e4c382"},"source":["# ネットワークの初期化\n","def weights_init(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        # conv2dとConvTranspose2dの初期化\n","        nn.init.normal_(m.weight.data, 0.0, 0.02)\n","        nn.init.constant_(m.bias.data, 0)\n","    elif classname.find('BatchNorm') != -1:\n","        # BatchNorm2dの初期化\n","        nn.init.normal_(m.weight.data, 0.0, 0.02)\n","        nn.init.constant_(m.bias.data, 0)\n","    elif classname.find('Linear') != -1:\n","        # 全結合層Linearの初期化\n","        m.bias.data.fill_(0)\n","\n","\n","# 初期化の実施\n","G.apply(weights_init)\n","E.apply(weights_init)\n","D.apply(weights_init)\n","\n","print(\"ネットワークの初期化完了\")\n"],"execution_count":21,"outputs":[{"output_type":"stream","text":["ネットワークの初期化完了\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yTL7xMf8vONm","executionInfo":{"status":"ok","timestamp":1615356298201,"user_tz":-540,"elapsed":523,"user":{"displayName":"Operational Amplifier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3etudnjCRnCXOZeYBsRUFbwA5_hCPRQvY_sSe=s64","userId":"13448740953613370666"}},"outputId":"3e9b3355-ad05-4201-a34a-57ab28378281"},"source":["type(train_dataloader)"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.utils.data.dataloader.DataLoader"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A15fc9YyvV5v","executionInfo":{"status":"ok","timestamp":1615356333858,"user_tz":-540,"elapsed":626,"user":{"displayName":"Operational Amplifier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3etudnjCRnCXOZeYBsRUFbwA5_hCPRQvY_sSe=s64","userId":"13448740953613370666"}},"outputId":"567f82df-d9d5-488f-9f00-3933bead75d6"},"source":["type(num_epochs)"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["int"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"0-eQCLPJL8K1","colab":{"base_uri":"https://localhost:8080/","height":439},"executionInfo":{"status":"error","timestamp":1615355764204,"user_tz":-540,"elapsed":33552,"user":{"displayName":"Operational Amplifier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3etudnjCRnCXOZeYBsRUFbwA5_hCPRQvY_sSe=s64","userId":"13448740953613370666"}},"outputId":"b5b189f5-6379-46eb-beed-6f728203a515"},"source":["# 学習・検証を実行する\n","# 15分ほどかかる\n","num_epochs = 1500\n","G_update, D_update, E_update = train_model(\n","    G, D, E, dataloader=train_dataloader, num_epochs=num_epochs)\n"],"execution_count":22,"outputs":[{"output_type":"stream","text":["使用デバイス： cpu\n","-------------\n","Epoch 0/1500\n","-------------\n","（train）\n"],"name":"stdout"},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-547dc0bc0793>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m G_update, D_update, E_update = train_model(\n\u001b[0;32m----> 5\u001b[0;31m     G, D, E, dataloader=train_dataloader, num_epochs=num_epochs)\n\u001b[0m","\u001b[0;32m<ipython-input-20-d3689a86475f>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(G, D, E, dataloader, num_epochs)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;31m# 誤差を計算\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0md_loss_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_out_real\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m             \u001b[0md_loss_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_out_fake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_loss_real\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md_loss_fake\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    715\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m                                                   reduction=self.reduction)\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   2824\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2826\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: result type Float can't be cast to the desired output type Long"]}]},{"cell_type":"code","metadata":{"id":"IL_pxhfEL8K5","executionInfo":{"status":"aborted","timestamp":1615355764195,"user_tz":-540,"elapsed":33539,"user":{"displayName":"Operational Amplifier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3etudnjCRnCXOZeYBsRUFbwA5_hCPRQvY_sSe=s64","userId":"13448740953613370666"}}},"source":["# 生成画像と訓練データを可視化する\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","# 入力の乱数生成\n","batch_size = 8\n","z_dim = 20\n","fixed_z = torch.randn(batch_size, z_dim)\n","G_update.eval()\n","fake_images = G_update(fixed_z.to(device))\n","\n","# 訓練データ\n","batch_iterator = iter(train_dataloader)  # イテレータに変換\n","imges = next(batch_iterator)  # 1番目の要素を取り出す\n","\n","\n","# 出力\n","fig = plt.figure(figsize=(15, 6))\n","for i in range(0, 5):\n","    # 上段に訓練データを\n","    plt.subplot(2, 5, i+1)\n","    plt.imshow(imges[i][0].cpu().detach().numpy(), 'gray')\n","\n","    # 下段に生成データを表示する\n","    plt.subplot(2, 5, 5+i+1)\n","    plt.imshow(fake_images[i][0].cpu().detach().numpy(), 'gray')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZKa9G-CZL8K7"},"source":["# テスト画像で異常検知する"]},{"cell_type":"code","metadata":{"id":"GcB7w-4xL8K8","executionInfo":{"status":"aborted","timestamp":1615355764198,"user_tz":-540,"elapsed":33539,"user":{"displayName":"Operational Amplifier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3etudnjCRnCXOZeYBsRUFbwA5_hCPRQvY_sSe=s64","userId":"13448740953613370666"}}},"source":["# テスト用のDataLoaderの作成\n","\n","\n","def make_test_datapath_list():\n","    \"\"\"学習、検証の画像データとアノテーションデータへのファイルパスリストを作成する。 \"\"\"\n","\n","    train_img_list = list()  # 画像ファイルパスを格納\n","\n","    for img_idx in range(5):\n","        img_path = \"./data/test_28size/img_7_\" + str(img_idx)+'.jpg'\n","        train_img_list.append(img_path)\n","\n","        img_path = \"./data/test_28size/img_8_\" + str(img_idx)+'.jpg'\n","        train_img_list.append(img_path)\n","\n","        img_path = \"./data/test_28size/img_2_\" + str(img_idx)+'.jpg'\n","        train_img_list.append(img_path)\n","\n","    return train_img_list\n","\n","\n","# ファイルリストを作成\n","test_img_list = make_test_datapath_list()\n","\n","# Datasetを作成\n","mean = (0.5,)\n","std = (0.5,)\n","test_dataset = GAN_Img_Dataset(\n","    file_list=test_img_list, transform=ImageTransform(mean, std))\n","\n","# DataLoaderを作成\n","batch_size = 5\n","\n","test_dataloader = torch.utils.data.DataLoader(\n","    test_dataset, batch_size=batch_size, shuffle=False)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ua6uY7_L8K-","executionInfo":{"status":"aborted","timestamp":1615355764199,"user_tz":-540,"elapsed":33536,"user":{"displayName":"Operational Amplifier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3etudnjCRnCXOZeYBsRUFbwA5_hCPRQvY_sSe=s64","userId":"13448740953613370666"}}},"source":["# テストデータの確認\n","batch_iterator = iter(test_dataloader)  # イテレータに変換\n","imges = next(batch_iterator)  # 1番目の要素を取り出す\n","\n","fig = plt.figure(figsize=(15, 6))\n","for i in range(0, 5):\n","    # 上段に訓練データを\n","    plt.subplot(2, 5, i+1)\n","    plt.imshow(imges[i][0].cpu().detach().numpy(), 'gray')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OB-bso3WL8LB","executionInfo":{"status":"aborted","timestamp":1615355764201,"user_tz":-540,"elapsed":33534,"user":{"displayName":"Operational Amplifier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3etudnjCRnCXOZeYBsRUFbwA5_hCPRQvY_sSe=s64","userId":"13448740953613370666"}}},"source":["def Anomaly_score(x, fake_img, z_out_real, D, Lambda=0.1):\n","\n","    # テスト画像xと生成画像fake_imgのピクセルレベルの差の絶対値を求めて、ミニバッチごとに和を求める\n","    residual_loss = torch.abs(x-fake_img)\n","    residual_loss = residual_loss.view(residual_loss.size()[0], -1)\n","    residual_loss = torch.sum(residual_loss, dim=1)\n","\n","    # テスト画像xと生成画像fake_imgを識別器Dに入力し、特徴量マップを取り出す\n","\n","    _, x_feature = D(x, z_out_real)\n","    _, G_feature = D(fake_img, z_out_real)\n","\n","    # テスト画像xと生成画像fake_imgの特徴量の差の絶対値を求めて、ミニバッチごとに和を求める\n","    discrimination_loss = torch.abs(x_feature-G_feature)\n","    discrimination_loss = discrimination_loss.view(\n","        discrimination_loss.size()[0], -1)\n","    discrimination_loss = torch.sum(discrimination_loss, dim=1)\n","\n","    # ミニバッチごとに2種類の損失を足し算する\n","    loss_each = (1-Lambda)*residual_loss + Lambda*discrimination_loss\n","\n","    # ミニバッチ全部の損失を求める\n","    total_loss = torch.sum(loss_each)\n","\n","    return total_loss, loss_each, residual_loss\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wl7OER2yL8LD","executionInfo":{"status":"aborted","timestamp":1615355764202,"user_tz":-540,"elapsed":33531,"user":{"displayName":"Operational Amplifier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3etudnjCRnCXOZeYBsRUFbwA5_hCPRQvY_sSe=s64","userId":"13448740953613370666"}}},"source":["# 異常検知したい画像\n","x = imges[0:5]\n","x = x.to(device)\n","\n","# 教師データの画像をエンコードしてzにしてから、Gで生成\n","E_update.eval()\n","G_update.eval()\n","z_out_real = E_update(imges.to(device))\n","imges_reconstract = G_update(z_out_real)\n","\n","# 損失を求める\n","loss, loss_each, residual_loss_each = Anomaly_score(\n","    x, imges_reconstract, z_out_real, D_update, Lambda=0.1)\n","\n","# 損失の計算。トータルの損失\n","loss_each = loss_each.cpu().detach().numpy()\n","print(\"total loss：\", np.round(loss_each, 0))\n","\n","# 画像を可視化\n","fig = plt.figure(figsize=(15, 6))\n","for i in range(0, 5):\n","    # 上段に訓練データを\n","    plt.subplot(2, 5, i+1)\n","    plt.imshow(imges[i][0].cpu().detach().numpy(), 'gray')\n","\n","    # 下段に生成データを表示する\n","    plt.subplot(2, 5, 5+i+1)\n","    plt.imshow(imges_reconstract[i][0].cpu().detach().numpy(), 'gray')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OPOfqd1VL8LE"},"source":["以上"]}]}